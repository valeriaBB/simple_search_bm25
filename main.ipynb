{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNj1Q0SzDcuIltPmRL4Rj+l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valeriaBB/simple_search_bm25/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8OWIj7_LzpU"
      },
      "outputs": [],
      "source": [
        "!wget http://ir.dcs.gla.ac.uk/resources/test_collections/cisi/cisi.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xvzf cisi.tar.gz"
      ],
      "metadata": {
        "id": "SmWW24xUMXu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rank-bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvK1TGcYcbEA",
        "outputId": "545122c4-f0fb-46d0-eaee-917cdc56b32f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.8/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rank-bm25) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from rank_bm25 import BM25Okapi\n"
      ],
      "metadata": {
        "id": "A9h3ch7yNFms"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/resource/CISI.ALL') as f:\n",
        "    lines = \"\"\n",
        "    for l in f.readlines():\n",
        "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
        "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
        "\n",
        "doc_set = {}\n",
        "doc_id = \"\"\n",
        "doc_text = \"\"\n",
        "for l in lines:\n",
        "  if l.startswith(\".I\"):\n",
        "      doc_id = l.split(\" \")[1].strip()\n",
        "  elif l.startswith(\".X\"):\n",
        "      doc_set[doc_id] = doc_text.lstrip(\" \")\n",
        "      doc_id = \"\"\n",
        "      doc_text = \"\"\n",
        "  else:\n",
        "      doc_text += l.strip()[3:] + \" \"\n",
        "\n",
        "\n",
        "with open('/content/resource/CISI.QRY') as f:\n",
        "    lines = \"\"\n",
        "    for l in f.readlines():\n",
        "      lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
        "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
        "  \n",
        "qry_set = {}\n",
        "qry_id = \"\"\n",
        "for l in lines:\n",
        "    if l.startswith(\".I\"):\n",
        "      qry_id = l.split(\" \")[1].strip()\n",
        "    elif l.startswith(\".W\"):\n",
        "      qry_set[qry_id] = l.strip()[3:]\n",
        "      qry_id = \"\"\n",
        "\n",
        "\n",
        "queries = qry_set\n",
        "documents = doc_set\n",
        "\n",
        "corpus = list(documents.values())\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "queries = list(queries.values())\n",
        "\n",
        "for x in range(0, len(queries)):\n",
        "  tokenized_query = queries[x].split(\" \")\n",
        "  doc_scores = bm25.get_scores(tokenized_query)\n",
        "  print(\"Query: \" + queries[x])\n",
        "  print(\"Score: \", doc_scores.max())\n",
        "\n",
        "  #print(queries[x])\n",
        "  #print(doc_scores)\n",
        "\n",
        "  bm25.get_top_n(tokenized_query, corpus, n=1)\n",
        "\n",
        "  print(\"Document: \", bm25.get_top_n(tokenized_query, corpus, n=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvUmhP3Pfaw1",
        "outputId": "05ea0ddd-82a7-4197-81e2-8dd9192bae94"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?\n",
            "Score:  52.52311881395261\n",
            "Document:  ['Information Science: What Is It? Borko, H. In seeking a new sense of identity, we ask, in this article, the question: What is information science? What does the information science do? Tentative answers to these questions are given in the hope of simulating discussion that will help clarify the nature of our field and our work.. ']\n",
            "Query: How can actually pertinent data, as opposed to references or entire articles themselves, be retrieved automatically in response to information requests?\n",
            "Score:  23.531543547248745\n",
            "Document:  ['Syntactic Structures Chomsky, N. This study deals with syntactic structure both in the broad sense (as opposed to semantics) and the narrow sense (as opposed to phonemics and morphology).  It forms part of an attempt to construct a formalized general theory of linguistic structure and to explore the foundations of such a theory.  The search for rigorous formulation in linguistics has a much more serious motivation than mere concern for logical niceties or the desire to purify well-established methods of linguistic analysis.  Precisely constructed models for linguistic structure can play an important role, both negative and positive, in the process of discovery itself.  By pushing a precise but inadequate formulation to an unacceptable conclusion, we can often expose the exact source of this inadequacy and, consequently, gain a deeper understanding of the linguistic data.  More positively, a formalized theory may automatically provide solutions for many problems other than those for which it was explicitly designed. Obscure and intuition-bound notions can neither lead to absurd conclusions nor provide new and correct ones, and hence they fail to be useful in two important respects. ']\n",
            "Query: What is information science?  Give definitions where possible.\n",
            "Score:  21.798262783359647\n",
            "Document:  ['Information Science: What Is It? Borko, H. In seeking a new sense of identity, we ask, in this article, the question: What is information science? What does the information science do? Tentative answers to these questions are given in the hope of simulating discussion that will help clarify the nature of our field and our work.. ']\n",
            "Query: Image recognition and any other methods of automatically transforming printed text into computer-ready form.\n",
            "Score:  17.397805459259867\n",
            "Document:  [\"Subject Indexes and Automatic Document Retrieval Lynch, Michael F. Index entries from the subject indexes to CA can, in general, be converted to 'normal' or title-like phrases by applying simple tests to the positions of prepositions and conjunctions in the entries.. Other, more complex, entries can be transformed after somewhat deeper analysis.. These manipulations are a necessary preliminary step to the use of the subject-index language in retrieval..A scheme is outlined for automatically compiling and editing subject indexes by transforming descriptive phrases with regular structure and vocabulary.. These transformations, based on the formal structure of language, are shown to be admirably suited to computer manipulation.. \"]\n",
            "Query: What special training will ordinary researchers and businessmen need for proper information management and unobstructed use of information retrieval systems? What problems are they likely to encounter?\n",
            "Score:  36.077256963428745\n",
            "Document:  [\"Economic Analysis of the Public Libraries Newhouse, J.P. This study addresses itself to several questions important to all public libraries.  How should the library allocate its book budget?  What kinds of books should it tend to buy?  What types of households use the library?  Why do some households not use the library?  What is the cost of the various services provided by the library?  What specific steps can the library take to improve its services?  What are the library's options in choosing among the different circulation systems?  For how long should the library allow books to be checked out?  How frequently should overdue notices be sent out?  Is an investment in a security system worthwhile? We have studied these questions in the context of one public library - the Beverly Hills (California) Public Library - and have developed a methodology for determining answers to them, as well as to other questions that arose during our investigation.  Although answers will vary from library to library, our methodology is quite general and should prove useful at many public libraries. \"]\n",
            "Query: What possibilities are there for verbal communication between computers and humans, that is, communication via the spoken word?\n",
            "Score:  26.445141860123044\n",
            "Document:  ['Theoretical Foundations of Thesaurus-Construction and Some Methodological Considerations for Thesaurus-Updating Kim, Chai It was argued that the present-day thesaurus-construction and maintenance rules and conventions are not theoretically based.. For this reason, there are few rules and conventions for updating a thesaurus.. Consequently, most of the thesauri adopted by operating information storage and retrieval systems are not systematically updated.. In order to investigate how thesauri are actually updated, a survey was conducted.. The working hypothesis was that the communication process between authors and readers is linear in nature (\"one-way\" communication allowing no reciprocal feedback) if a thesaurus utilized in a system is not updated by both indexers and question negotiators.. Findings show that thesauri viewed from the communications point of view do not allow a cybernetic process of communication (\"both-way\" communication).. The survey indicated that the present practice of updating thesauri is largely done by indexers alone.. No attempt was made to develop a theory of thesaurus construction and updating.. It was, however, argued that such a theory, if developed, should at least account for the concepts of meaning and knowledge.. Within this theoretical framework, two techniques are suggested to be considered for the systematic updating of a thesaurus.. ']\n",
            "Query: Describe presently working and planned systems for publishing and printing original papers by computer, and then saving the byproduct, articles coded in data-processing form, for further use in retrieval.\n",
            "Score:  39.992640804718334\n",
            "Document:  ['The Automatic Creation of Literature Abstracts Luhn, H.P. Experts of technical papers and magazine articles that serve the purposes of conventional abstracts have been created entirely by automatic means.. In the exploratory research described, the complete text of an article in machine- readable form is scanned by an IBM 704 data-processing machine and analyzed in accordance with a standard program..  Statistical information derived from word frequency and distribution is used by the machine to compute a relative measure of significance, first for individual words and then for sentences.. Sentences scoring highest in significance are extracted and printed out to become the \"auto-abstract\".. ']\n",
            "Query: Describe information retrieval and indexing in other languages. What bearing does it have on the science in general?\n",
            "Score:  27.175217056635024\n",
            "Document:  ['Information Science: What Is It? Borko, H. In seeking a new sense of identity, we ask, in this article, the question: What is information science? What does the information science do? Tentative answers to these questions are given in the hope of simulating discussion that will help clarify the nature of our field and our work.. ']\n",
            "Query: What possibilities are there for automatic grammatical and contextual analysis of articles for inclusion in an information retrieval system?\n",
            "Score:  30.832609434921405\n",
            "Document:  ['A Grammatical Elements in a Descriptor Language for an Information Retrieval System Ivanova, N. I. Margaritov, V. B. The results are described of research and development activities of the Mechanized Information Retrieval Laboratory of the NIITEKHIM.. Research Institute aimed towards creating a descriptor language for an information retrieval system in the field of chemistry and chemical engineering.. The objectives of an optimum reduction of retrieval noise and maximum recall have required the introduction of grammatical and transformational devices into the language.. The former condition is provided for by a matrix notation of document search patterns and requests, while the latter condition is met with the help of the transformational devices of the language.. Examples of search requests and patterns are considered, which illustrate the \"resolution\" of the grammatical and transformational devices being developed.. These are said largely to eliminate subjectiveness in assigning relational factors in search patterns and requests.. The relevancy criterion is formulated.. A retrieval algorithm based on this criterion has been compiled.. Experimental searches were conducted on a Minsk-22 computer.. The results were analyzed to evaluate the grammatical and transformational devices and to verify indexing principles devised for the automated retrieval system under development.. Factors of \"silence\" are discussed, as well as the contribution of the grammatical and transformational devices to reducing noise and enhancing recall.. ']\n",
            "Query: The use of abstract mathematics in information retrieval, e.g. group theory.\n",
            "Score:  27.290553343598788\n",
            "Document:  ['Structural Models:  an introduction to the theory of directed graphs Harary, F. The purpose of this book is to present an introduction to a body of mathematics concerned with the abstract notion of \"structure.\"  Its preparation has been motivated by the belief that knowledge of the mathematics of abstract structures will be of value to investigators interested in various kinds of empirical structures.  The mathematics with which we are concerned is known as the theory of directed graphs, or more briefly as digraph theory.  It deals with abstract configurations called digraphs, which consist of \"points\" and \"directed lines.\"  When these terms are given concrete referents, digraphs serve as mathematical models of empirical structures, and properties of digraphs reflect structural properties of the empirical world.  Since the same mathematical terms can be given a variety of empirical meanings, digraph theory has applicability to many different fields of investigation. ']\n",
            "Query: What is the need for information consolidation, evaluation, and retrieval in scientific research?\n",
            "Score:  21.442462775365357\n",
            "Document:  [\"Information Retrieval and Processing Doyle, L.B. The present book embodies a change in structure and focus to reflect the fact that the reader of today's book is much more likely to be an interested college student with a great awareness of the current information revolution than was the case ten years ago.  Thus, hardware, materials, and processes used in connection with information systems are discussed first, in Chapters Two through Four.  The subject of information retrieval per se begins with Chapters Five and Six, which have to do with librarianship and documentation.  Because of their somewhat historical slant, these chapters (along with Seven) are the only ones taken from the 1963 book which adhere to their original character.  Chapter Seven presents a simplified concept of an information system and its components, and paves the way for discussion of computerized retrieval in the chapters to follow, especially for data retrieval in Chapter Eight and document retrieval in Chapter Nine. Chapters Ten through Twelve, on language processing, evaluation, and user studies, describe important facets of the information retrieval field that have developed strongly since 1963. \"]\n",
            "Query: Give methods for high speed publication, printing, and distribution of scientific journals.\n",
            "Score:  18.06612461859771\n",
            "Document:  ['Concerning the Criterion for Evaluation of Current Secondary Information Zilbermints, L.V. The findings are described of a study aimed at determining the prospects and methods for improving the system of current bibliographic information..  The analysis has shown that the existing criteria for evaluation of special bibliographies (scope, coverage, arrangement, speed of announcement, etc.) are inadequate for an unbiased characterization of their exhaustivity and subject contents..  This hampers a correct choice of the sources of secondary information and leads to duplication, parallelisms and loss of information.. Judgements of the leading Soviet and foreign bibliographers relating to the problems under consideration are reviewed, which are all essentially in favor of a reconstruction of the publishing processes, issuing of scientific publications on a world scale, and algorithmization of the information processes..  It is suggested that the first objective of research should be a method of comparative evaluation of periodicals.. ']\n",
            "Query: What criteria have been developed for the objective evaluation of information retrieval and dissemination systems?\n",
            "Score:  27.607780940068082\n",
            "Document:  ['What Information Dissemination Studies Imply Concerning the Design of On-Line Reference Retrieval Systems* Back, Harry B. The use of an on-line computer system for locating bibliographic citations has been hailed as an important innovation for coping with the \"information explosion..\" However, on-line reference retrieval is only one element in a large social system of information dissemination.. To have a widespread impact, an on-line system must compete successfully with a multitude of other sources of references.. This paper reviews studies of information dissemination as a basis for determining how on-line retrieval can best compete.  It recommends the functional groups for whom an on-line system should be designed and the forms of written media that should be included in the system\\'s initial data base.. Finally, it presents criteria the system should satisfy to be as widely used and as comprehensive as other reference retrieval methods.. ']\n",
            "Query: What future is there for automatic medical diagnosis?\n",
            "Score:  14.966292578366044\n",
            "Document:  ['Libraries and Technological Forces Affecting Them Cuadra, C.A. 1.  What do we mean by technology and what kind of technological forces are we concerned with? 2.  Why is it important to be concerned with technology in thinking about the future of libraries? 3.  What kinds of technology are particularly important for libraries? 4.  How can this technology be applied today? 5.  What can we foresee for the future, as we move toward the year 2000? 6.  What, if anything, should we do tomorrow to try to get from here to here? ']\n",
            "Query: How much do information retrieval and dissemination systems, as well as automated libraries, cost? Are they worth it to the researcher and to industry?\n",
            "Score:  29.07239866848081\n",
            "Document:  ['Measures of the Usefulness of Written Technical Information to Chemical Researchers Kegan,  Daniel L. The effective transfer of technology involves more than just distributing paper; it demands that useful documents be disseminated with a minimum of useless ones.. For 1 month, 10 researchers recorded a sample of the written technical information items that they received; 4 months later they were interviewed to determine which of these items had proved useful, and in what ways.. The results indicate that (1) a researcher will call an item \"useful\" even if it does not cause him to take some action, but only has some significance for him; (2) the more the source of an item knows about the needs of the researcher or the more the researcher knows about an item he seeks, the more likely it is that the researcher will find the item useful; (3) no strong relationships were found between certain readily observable, physical arrangements and information behavior; and (4) an item may prove useful, not because of the information objectively contained in that item, but because the item causes a cognitive restructuring of the researcher\\'s mind or a \"free association.\" Other studies that restrict their measures of information usefulness to externally observable behavior or that do not carefully define usefulness may not be validly representing usefulness to the researcher.. ']\n",
            "Query: What systems incorporate multiprogramming or remote stations in information retrieval?  What will be the extent of their use in the future?\n",
            "Score:  36.33869519032952\n",
            "Document:  ['Information Science: What Is It? Borko, H. In seeking a new sense of identity, we ask, in this article, the question: What is information science? What does the information science do? Tentative answers to these questions are given in the hope of simulating discussion that will help clarify the nature of our field and our work.. ']\n",
            "Query: Means of obtaining large volume, high speed, customer usable information retrieval output.\n",
            "Score:  15.688196564141064\n",
            "Document:  ['On-Line Systems: Promise and Pitfalls Cuadra, Carlos A. Interactive systems, in existence for nearly 15 years, are becoming increasingly important, both for information retrieval and library support operations.. The virtues of these systems are speed, intimacy, and - if time-sharing is involved - economy.. The major problems are the cost of the large computers and files necessary for bibliographic data, the still- high cost of communications, and the generally poor design of the user- system interfaces.. The desirable features of on-line retrieval interfaces are only now being defined and tested in a systematic way, e.g., by the National Library of Medicine in its AIM-TWX nationwide experimental retrieval service.. System implementers must, in addition to engineering the right capabilities into on-line systems, also make a careful, concerted effort to engineer user acceptance.. Common pitfalls here include overselling system capabilities and failure to take into account the social context around the user terminal.. The major national problem is to avoid or limit wasteful and expensive duplication in providing nationwide search access to the hundreds of public and private data bases that will be readily available during the next few years.. We do not need technological breakthroughs to exploit the potential of on-line systems, but we do need breakthroughs in organizing for technological change.. ']\n",
            "Query: What methods are there for encoding, automatically matching, and automatically drawing structures extended in two dimensions, like the structural formulas for chemical compounds?\n",
            "Score:  37.20508133799685\n",
            "Document:  ['The Automatic Encoding of Chemical Structures Feldman, A. Holland, D.B. Jacobus, D.P. Many methods for the coding of chemical structures have been described in the literature.\\tSome methods code the compound only partially; typical of these are the methods using descriptor codes.  Other methods, among which the so-called ciphers are prominent, code compounds exhaustively.  All these methods require cerebral effort; that is, a chemist is needed who must have learned the rules of the code, and who must known how to dismember correctly each structure to be coded.  A disadvantage of code designations of structures is, furthermore, that they are not generally understood by chemists.  No advantages accrue to the chemist from knowing how to generate and how to interpret a chemical code.\\tCodes are needed only for the mechanical manipulation of chemical structures.  Clearly then, if the coding of chemical compounds could be accomplished automatically this automatic conversion would relieve the chemist of considerable burden. ']\n",
            "Query: Techniques of machine matching and machine searching systems. Coding and matching methods.\n",
            "Score:  27.960620508016465\n",
            "Document:  ['Automatic information, organization and retrieval Salton, G. This book deals with the computer processing of large information files, with special emphasis on automatic text handling methods. Described in particular are procedures for dictionary construction and dictionary look-up, statistical and syntactic language analysis methods, information search and matching procedures, automatic information dissemination systems, and methods for user interaction with the mechanized system.  As such, the text includes elements of linguistics, mathematics, and computer programming. ']\n",
            "Query: Testing automated information systems.\n",
            "Score:  10.363047084031024\n",
            "Document:  [\"Automated Acquisitions Procedures at the University of Michigan Library Dunlap, C. In June 1965, the Acquisitions Department of The University of Michigan Library began using a computer-based system for ordering books and other library materials.  This is the beginning of an over-all automated system for the Acquisitions Department and was designed with the assistance of Robert O. Kindt, Systems Analyst from the University's Office of Management Services.  Preliminary work on the automated system was begun in late 1963, and in September, 1964.  Mr. Kindt was assigned to the University Library on a full-time basis.  After the preliminary proposal was drafted, cost and feasibility studies were made.  Current (i.e., 1964) volume and costs were compared with anticipated volume and costs in 1968 and 1975 for both manual and automated systems. \"]\n",
            "Query: The need to provide personnel for the information field.\n",
            "Score:  18.182345245039325\n",
            "Document:  [\"The Hidden Dimension Hall, E.T. Generally speaking, there are two types of books of interest to the serious reader today:  those that are content oriented, designed to convey a particular body of knowledge, and those that deal with structure, the way in which events are organized.  It is doubtful if an author has any control over which of these two types of books he writes, though it is desirable that he be aware of the difference.  The same applies to the reader whose satisfaction depends largely on his unstated expectations.  In today's world, when all of us are overwhelmed with data from many sources, it is easy to understand why people are apt to feel that they are losing touch with developments even in their own field.  One senses that there is also a growing awareness of a loss of relatedness to the world at large.  This loss of relatedness leads to an increased need for organizing frames of reference to aid in intergrating the mass of rapidly changing information with which man must cope. The Hidden Dimension attempts to provide just this. \"]\n",
            "Query: Automated information in the medical field.\n",
            "Score:  13.351099701998034\n",
            "Document:  [\"The Medical Library Assistance Act: An Analysis of the NLM Extramural Programs, 1965-1970 Cummings, Martin M. Corning, Mary E. The imbalance between medical library resources and information needs of the health professional led to a reexamination of the mandate for the National Library of Medicine.. Legislation known as the Medical Library Assistance Act (MLAA) was passed in 1965 which enabled the NLM to (1) initiate programs to assist the nation's medical libraries and (2) develop a medical library network with the establishment of regional medical libraries to link the NLM with local institutions.. The National Library of Medicine, through the MLAA, has made available $40.8 million to the medical library community under a competitive grant and contract mechanism for the period July 1965 - June 1970.. A total of 604 projects has been executed in resources, research and development, training, construction, regional medical libraries, publications, and special scientific projects.. An assessment is given of each of these programs and their impact on both the National Library of Medicine and individual medical libraries.. In the aggregate, these programs have significantly improved library and information services to the professional health user.. The principal limitation has been inadequate funding to accomplish the level of originally stated objectives.. \"]\n",
            "Query: Amount of use of books in libraries. Relation to need for automated information systems .\n",
            "Score:  27.79780149720399\n",
            "Document:  ['Networks for Research and Education Greenberger, M. Responding to the heightened interest in the possibilities of networks, and reflecting its own continuing interest in improving the use of new technologies in research and education, the National Science Foundation in 1972 announced the mounting of \"an expanded research program . . . to explore . . . the resource-sharing potential of a national network in support of research and education.\"  The NSF was well aware of the obstacles and uncertainties, and it knew that although shareable resources and pockets of relevant information and experience existed, many of the people who should be involved in planning were not currently informed or discussing the possibilities with one another. ']\n",
            "Query: Educational and training requirements for personnel in the information field. Possibilities for this training.  Needs for programs providing this training.\n",
            "Score:  38.867756140975445\n",
            "Document:  [\"Job Dimensions and Educational Needs in Librarianship Kertendick, T.T. This study was undertaken to meet more fully the demands for improved and expanded training of library personnel, especially at the middle and upper levels, occasioned by the rapidly changing roles and functions of libraries as they try to adapt to the vast social, economic, and technological changes currently in progress.  The rise to a higher level of required skills and competencies - often new - has brought about an urgent need for improved training beyond the first professional degree at the post-master's level.  The basic purpose of this research is curriculum development at the post-master's level that will equip the middle- and upper-level personnel in libraries for the changes confronting them.  Although it would be possible to restructure the master's program and add the courses that this study shows a need for, that alternative has not been pursued for two reasons: a fairly stable master's curriculum is widely accepted and institutionalized and, more important, the new courses are designed for a different group of students - experienced librarians. \"]\n",
            "Query: International systems for exchange and dissemination of information.\n",
            "Score:  19.056551523854157\n",
            "Document:  ['International Standardization of Cataloguing and Bibliographical Records: The Work of the IFLA Committee on Cataloguing Anderson, D. The ILFA Committee on Cataloguing has been at work since 1954 to establish international standards for cataloguing and bibliographical records, and was responsible for the International conference on Cataloguing Principles, Paris, 1961, and the International Medical of Cataloguing Experts, Copenhagen, 1969.  A new impetus to its work has been given in 1971 with the establishment of its permanent Cataoguing Secretariat whose function were to act as a co-ordinating centre, to promote cataloguing projects and to disseminate information. ']\n",
            "Query: Cost and determination of cost associated with systems of automated information.\n",
            "Score:  22.173242127310274\n",
            "Document:  ['Scope: A Cost Analysis of an Automated Serials Record System Koenig, Michael E. Finlay, Alexander C. Cushman, Joann G. Detmer, James M. A computerized serials record and control system developed in 1968/69 for the Technical Information Department of Pfizer Inc. is described and subjected to a cost analysis.. This cost analysis is conducted in the context of an investment decision, using the concept of net present value, a method not previously used in library literature.. The cost analysis reveals a positive net present value and a system life break-even requirement of seven years at a 10% cost of capital.. This demonstrates that such an automated system can be economically justifiable in a library of relatively modest size (approx. 1,100 serial and periodical titles).. It may be that the break-even point in terms of collection size required for successful automation of serial records is smaller than has been assumed to date.. ']\n",
            "Query: Computerized information retrieval systems.  Computerized indexing systems.\n",
            "Score:  19.049919969819392\n",
            "Document:  ['Vocabulary Control for Information Retrieval Lancaster, F.W. This book deals with properties of vocabularies for indexing and searching document collections; the construction, organization, display, and maintenance of these vocabularies; and the vocabulary as a factor affecting the performance of retrieval systems.  Most of the text is concerned with vocabularies for post- coordinate retrieval systems, with special emphasis on thesauri and machine-based systems.  Vocabularies for pre-coordinate systems (e.g., alphabetical subject catalogs and classified catalogs) are discussed only briefly to provide historical perspective and for the light they shed on the problems o vocabulary control in general.  This type of vocabulary is well covered in existing texts. ']\n",
            "Query: Computerized information systems in fields related to chemistry.\n",
            "Score:  13.544351856165383\n",
            "Document:  ['System Analysis in University Libraries Leimkuhler, Ferdinand F. A comprehensive enginnering approach to the analysis and functional design of library systems is described in terms of fundamental space-time relationship which characterize university libraries.. Long-run trends in aquisitions and circulation are related to the relative obsolescence of stored materials, and the uncertainty of short-run demand pattern is related to the need for excess service capability.. The spatial dispertion of library resources among specialized information centers and central depositories is considered with respect to availability, retrieval, duplication, and efficient storage.. ']\n",
            "Query: Specific advantages of computerized index systems.\n",
            "Score:  12.47471304097019\n",
            "Document:  ['Chemical Abstracts Index Names for Chemical Substances in the Ninth Collective Period (1972-1976) Donaldson, N. Powell, W.H. Rowlett, R.J. White, R.W. Yorka, K.V. Index names for chemical substances have been significantly revised by Chemical Abstracts Service (CAS) for Volume 76 [January-June 1972, the first volume of the Ninth Collective Period (1972-1976)] and subsequent volumes of Chemical Abstracts.  While remaining generally within the framework of IUPAC and other existing nomenclature rules, the most systematic recommended names have been chosen.  These names are more easily derived from molecular structural diagrams, and, therefore, are more quickly found by index users.  Machine editing of index names and translation of these names into structural representations in the CAS computer-based information system are also aided by the revisions.  The index name revisions include (i) conversion of almost all \"trivial\" or author terminology into more systematic names, (ii) simplification of general name-selection rules, and (iii) elimination of special treatment for certain classes of substances.  Specific identifiable alloys, elementary particles, enzymes, and mixtures of substances are now indexed like conventional chemical substances.  Difficulties encountered with generation of previous Chemical Abstracts index names and indexing rules are described, and comparisons are made of new and former index names for chemical compounds and substituent radicals. ']\n",
            "Query: Information dissemination by journals and periodicals.\n",
            "Score:  10.71281901956131\n",
            "Document:  ['Statistics of Scientific and Technical Articles Vickery, B.C. A new estimate of the number of currently published scientific and technical periodicals has been put forward by K.P. Barr of the National Lending Library.  It may be of interest to supplement this with some figures on the number and distribution of articles within these periodicals.  These figures are derived from a survey undertaken at the NLL early in 1964. ']\n",
            "Query: Information systems in the physical sciences.\n",
            "Score:  17.39791770126137\n",
            "Document:  ['Bibliographical Reference Patterns in Core Sociological Journals, 1965-1966 Lin, N. Nelson, C.E. The present study attempted to extend previous work on bibliographical reference patterns in sociological journals in the following ways: (1) by selecting for study those journals to which American sociologists prefer to submit their work, (2) by including, over a two-year period, all bibliographical references (journals, books, technical reports, etc.), and (3) by including, for initial comparison, a journal from the physical sciences.  Such a study, it was hoped, would yield data concerning similarities and differences among the sociological journals and between the sociological journals and the physical science journal. ']\n",
            "Query: Attempts at computerized and mechanized systems for general libraries. Problems and methods of automated general author and title indexing systems.\n",
            "Score:  30.610029408369\n",
            "Document:  ['Title Derivative Indexing Techniques; a comparative study Feinberg, H. The increasing volume of published literature continues to present problems in relation to information handling and information representation. As the magnitude and complexity of the available information has continued to increase, investigators have examined means of reducing the costly and time-consuming processes involved when human beings assign index terms to documents.  Recognition of the general inadequacy of present indexing, and concern over time and cost factors in index preparation have prompted experimentation in the development and application of machines to assist in the indexing process.  As a result, use of suitable mechanized or partly mechanized procedures to replace or complement the manual indexing process has become more widespread.  Machine indexing is a process whereby mechanized or automatic selection or generation of indexing terms is accomplished.  The present study investigates one aspect of automatic computer-based indexing, the permuted title index. ']\n",
            "Query: Retrieval systems which provide for the automated transmission of information to the user from a distance.\n",
            "Score:  30.026669299617367\n",
            "Document:  ['Improving Access to Library Resources Dougherty, R.M. The motivation for this investigation derived from a series of visits to institutions which were deeply committed to the design, development, and operation of non-traditional automated information systems.  At the time of the visits, the systems seemed to be working technically but, paradoxically, they did not appear to have made a significant impact on the respective user communities.  Although few people associated with the systems openly expressed concern, there were non-verbal indicators which suggested that some people were becoming nervous. Since all of the systems represented high expenditures of time and money, a feeling of uneasiness seemed quite appropriate. ']\n",
            "Query: Methods of coding used in computerized index systems.\n",
            "Score:  16.948162242569822\n",
            "Document:  ['A Notation for Coding Organic Compounds Geivandov, E. A. A notation for coding organic structures has been developed which provides for very simple and rational rules of coding the common cyclic fragments.. The conventional unit used in coding regular structures is benzol ring, and the skeleton of the regular condensed system is coded using a sequence of even and odd integers.. The set of rules for coding regular systems might be used as component of a universal notation for organic compounds.. The code offered by the author is designed to cover an important and broad class of compounds with conjugate bonds and it can be used within the framework of a specialized computer-based information retrieval system in the capacity of both the input and the internal machine language.. ']\n",
            "Query: Government supported agencies and projects dealing with information dissemination.\n",
            "Score:  13.12231600320651\n",
            "Document:  ['International Developments in Cataloging Anderson, Dorothy The IFLA Committee on Cataloging has been at work since 1954 to establish international standards for cataloging and bibliographic records; it was responsible for the International Conference on Cataloging Principles, Paris, 1961, and and the International Meeting of Cataloging Experts, Copenhagen, 1969.. In recent years there have been increasing demands from national cataloging bodies and bibliographic agencies for uniformity in codes and practices, and in consequence there has been more willingness to make national concessions in order to reach international standards.. The IFLA Cataloging Secretariat was established in 1971 to assist this trend by co-ordinating work, promoting new projects and acting as a liaison center.. ']\n",
            "Query: What are some of the theories and practices in computer translating of texts from one national language to another?  How can machine translating compete with traditional methods of translating in comprehending nuances of meaning in languages of different structures?\n",
            "Score:  66.88891103841405\n",
            "Document:  ['On basic features of information retrieval language for information retrieval by title. Stokolova, N.H. Veeduts, F.E. Presents the basic features of variants of an informational language designed for searching titles of publications in the field of synthetic organic chemistry. The classification of terms from natural language and the specifics of translating them into information language are discussed. A method for selecting the synthetic means of informational languages is developed, and the criterion for semantic correspondence and search algorithm is briefly described. Experiments which were conducted with 3 variants of the language developed are discussed. Conclusions are drawn on the benefits of the languages for searching, recommendations are made regarding their field of application. ']\n",
            "Query: What lists of words useful for indexing or classifying material are available?  Wanted are lists of terms that are descriptive vocabularies of particular fields or schedules of words that are related to each other in meaningful schemes.  Wanted are lists that have been tested, at least to some extent, and found useful for organizing material and for retrieving it.\n",
            "Score:  82.51333690302832\n",
            "Document:  [\"Compound Words: A Problem in Post-Coordinate Retrieval Systems Jones, Kevin P. Compound words cause some difficulty in post-coordinate indexing systems:  if too many are fractured, or the wrong categories are selected for fracturing, noise will be produced at unacceptable levels on retrieval.. Various prior suggestions for handling compound terms are examined which include those for pre-coordinated or rotated, indexes.. The syntactic origins are also explored and it is found that many compound words hinge on a prepositional relationship between the components, and that this relationship can be applied to decision making.. Other compound words are in effect abbreviated statements from longer phrases, while some are influenced by the presence of a verb-like form.. These syntactic influences, together with some of the philosophy from earlier studies - especially that of the 'force' required to fracture a term, have been combined to produce a set of rules which have been employed at the National Rubber Producers' Research Association (NRPRA) for over two years.. These have greatly eased decision making and have enabled the thesaural vocabulary to be made more consistent.. It is also suggested that the rules have some bearing on the application of roles especially if these are employed on a pre-coordinate basis.. \"]\n",
            "Query: How can access words in an information retrieval system be kept up to date? Word meanings and usage often change and lists must be dynamic to be current. What definitions of the problem and progress toward solutions have been made in providing necessary flexibility in systems of subject headings, index words, or other symbols used for getting at stored data?\n",
            "Score:  58.805620700524884\n",
            "Document:  ['Subject Analysis: Computer Implications of Rigorous Definator Harris, J.L. Subject analysis for information retrieval is an area which always seems deceptively simple to those without previous background in it, however extensive their background in specific subject disciplines may be.  The basic requirement seems easy enough: to structure the statement of a subject in such a way that it can be placed into, and retrieved from, an ordered file. While attempts have been made to use simple, non-complex terms or even single words, it always becomes evident that single words are often insufficient to express a subject, and that some subjects are in themselves complex. To express such subjects requires either that their constituent concepts -- not words -- be separated and then recombined, or that only one part of the subject be shown. The former solution requires that the indexer perform the necessary analysis and synthesis, and then separate the constituents for the searcher to reassemble.  The latter forces the seeker of information to sort through many items to find those bearing on the complex topic he wants, and ma require the indexer to decide under which part(s) of the concept an entry should be made. ']\n",
            "Query: The progress of information retrieval presents problems of maladjustment and dislocation of personnel.  Training and retraining of people to use the new equipment is important at all levels.  Librarians, assistants, technicians, students, researchers, and even executives will need education to learn the purpose, values, and uses of information systems and hardware. What programs have been developed to change the attitudes and skills of traditional workers and help them to learn the newer techniques?\n",
            "Score:  103.01817561138532\n",
            "Document:  [\"A Guide to the Construction and Use of Special Schemes Vickery, B.C. The use of classification in libraries is traditional and its value is appreciated.  For documentation and information retrieval in general, other techniques such as alphabetical indexing and machine selection are also available.  That classification is of value in information retrieval as well as in book arrangement is, however, made evident in two ways.  First, to achieve consistency and subtlety in alphabetical indexing and machine selection designers of such retrieval systems find the need to introduce classificatory techniques.  Second, there is a continuing demand for the construction of special classifications for detailed arrangement and cataloguing of documents in restricted but intensively cultivated fields of knowledge. It is to help meet these demands, particularly the second, that this guide has been prepared.  The techniques of detailed depth classification have been greatly developed during the past decade, and instruments of much greater subtlety and efficiency than the traditional 'tree-of-knowledge' schemes can now be designed. These developments have been reported mainly as research papers in a variety of library journals and are often made unnecessarily difficult to follow by the use of unfamiliar terminology. There is a need for a more simply written and more readily available practical guide to the use of the newer techniques of classification. \"]\n",
            "Query: What is the status of machine translation?  What progress has been made in the use of computers to transfer from one language to another with some degree of automation?  What problems and stumbling blocks have been found and are they considered to be insurmountable limitations or only challenging to the field of documentation on an international scale?\n",
            "Score:  78.8830199196732\n",
            "Document:  [\"Economic Analysis of the Public Libraries Newhouse, J.P. This study addresses itself to several questions important to all public libraries.  How should the library allocate its book budget?  What kinds of books should it tend to buy?  What types of households use the library?  Why do some households not use the library?  What is the cost of the various services provided by the library?  What specific steps can the library take to improve its services?  What are the library's options in choosing among the different circulation systems?  For how long should the library allow books to be checked out?  How frequently should overdue notices be sent out?  Is an investment in a security system worthwhile? We have studied these questions in the context of one public library - the Beverly Hills (California) Public Library - and have developed a methodology for determining answers to them, as well as to other questions that arose during our investigation.  Although answers will vary from library to library, our methodology is quite general and should prove useful at many public libraries. \"]\n",
            "Query: Is alphabetical ordering of material considered to be a useful tool in information retrieval?  What studies have been done to compare the effectiveness of alphabetical order with other organization schemes? Is there a generally accepted form of arranging material in alphabetical order, and is there an easy way of achieving this form without going to a great amount of effort?\n",
            "Score:  76.13933575264572\n",
            "Document:  [\"A Guide to the Construction and Use of Special Schemes Vickery, B.C. The use of classification in libraries is traditional and its value is appreciated.  For documentation and information retrieval in general, other techniques such as alphabetical indexing and machine selection are also available.  That classification is of value in information retrieval as well as in book arrangement is, however, made evident in two ways.  First, to achieve consistency and subtlety in alphabetical indexing and machine selection designers of such retrieval systems find the need to introduce classificatory techniques.  Second, there is a continuing demand for the construction of special classifications for detailed arrangement and cataloguing of documents in restricted but intensively cultivated fields of knowledge. It is to help meet these demands, particularly the second, that this guide has been prepared.  The techniques of detailed depth classification have been greatly developed during the past decade, and instruments of much greater subtlety and efficiency than the traditional 'tree-of-knowledge' schemes can now be designed. These developments have been reported mainly as research papers in a variety of library journals and are often made unnecessarily difficult to follow by the use of unfamiliar terminology. There is a need for a more simply written and more readily available practical guide to the use of the newer techniques of classification. \"]\n",
            "Query: The average student or researcher has difficulty in comprehending the vocabulary of information retrieval.  It appears important that this new field be understood before it is to be fully accepted.  What basic articles would provide an understanding of the various important aspects of the information storage and retrieval?\n",
            "Score:  59.44332559866341\n",
            "Document:  [\"The Annual Review of Information Science and Technology Cuadra, C.A. 1969 This, the fourth volume of the Annual Review of Information Science and Technology, is both like and unlike its predecessors.  The basic objective - to provide the most comprehensive and technically sound progress review ever prepared in the information science field - remains the same, as do the basic areas of interest and coverage.  Too, the primary emphasis continues to be on published literature and reports, to permit the reader to identify, locate, and examine interesting and important sources of information about various aspects of our technical progress. Some new areas of growing importance are introduced this year.  For the first time, a chapter on reprography and microfilm technology and one on the international aspects of information transfer have been included.  Also, the topics of document dissemination and the secondary services, usually covered in parts of other chapters, have full and separate chapters this year.  Another change, made in response to suggestions from readers for better signposts within each volume, is the division of the book into several major segments, each introduced by a short description of the contents of the section, the relationships among the chapters within it, and, in some instances, one or two highlights of the year's technical progress. \"]\n",
            "Query: The difficulties encountered in information retrieval systems are often less related to the equipment used than to the failure to plan adequately for document analysis, indexing, and machine coding.  The position of the programmer is to take a problem and write it in a way in which the equipment will understand.  What articles have been written describing research in maximizing the effectiveness of programming?\n",
            "Score:  93.30610249348587\n",
            "Document:  [\"A Guide to the Construction and Use of Special Schemes Vickery, B.C. The use of classification in libraries is traditional and its value is appreciated.  For documentation and information retrieval in general, other techniques such as alphabetical indexing and machine selection are also available.  That classification is of value in information retrieval as well as in book arrangement is, however, made evident in two ways.  First, to achieve consistency and subtlety in alphabetical indexing and machine selection designers of such retrieval systems find the need to introduce classificatory techniques.  Second, there is a continuing demand for the construction of special classifications for detailed arrangement and cataloguing of documents in restricted but intensively cultivated fields of knowledge. It is to help meet these demands, particularly the second, that this guide has been prepared.  The techniques of detailed depth classification have been greatly developed during the past decade, and instruments of much greater subtlety and efficiency than the traditional 'tree-of-knowledge' schemes can now be designed. These developments have been reported mainly as research papers in a variety of library journals and are often made unnecessarily difficult to follow by the use of unfamiliar terminology. There is a need for a more simply written and more readily available practical guide to the use of the newer techniques of classification. \"]\n",
            "Query: There are presently fifty to one hundred technical journals being published.  On the average, two new journals appear every day.  In the many journals published, one to two million articles appear every year.  What attempts have been made to cope with this amount of scientific and technical publication in terms of analysis, control, storage, and retrieval?\n",
            "Score:  74.73537295127889\n",
            "Document:  ['Indivisible Colleges; Diffusion of Knowledge in Scientific Communities Crane, D. In the last two decades, dramatic increases in the scope and volume of scientific research have occurred, as may be illustrated by the fact that the amount of scientific literature is doubling approximately every ten years (Price 1963).  For the scientist who needs to locate particular items of scientific information and for the documentation specialist who must make them readily available, the organization and management of this huge and expanding store of information is a serious problem.  Increasingly radical solutions are being proposed.  For example, some experts would like to scrap scientific journals and distribute their contents piecemeal. Information retrieval and delivery systems are being developed to enable scientists to locate information quickly and effectively. ']\n",
            "Query: I am looking for information about the impact of automation on libraries and its significance for libraries in general.  This includes the increasing importance of automation in view of the proliferation of information today, and how automation can help libraries cope with this problem.  How will automation affect libraries and how should they react to the idea of automation?\n",
            "Score:  90.35049840773851\n",
            "Document:  ['Guidelines for Library Automation; a Handbook for Federal and Other Libraries Markuson, B.E. This book is one of the products of a contract initiated by the Automation Task Force of the Federal Library Committee, sponsored and monitored by the U.S. Office of Education, and carried out by the System Development Corporation.  The project included a questionnaire survey of all Federal libraries (2104), as of December, 1970, to gather systems planning data and to identify Federal libraries with operational or planned automated systems. Respondents in the latter group were sent a Federal Library Automation Survey questionnaire requesting specific details about existing and planned systems. From these sources, amplified by visits to Federal libraries and an extensive review of the automation literature, information was distilled for use in this Handbook. ']\n",
            "Query: I am seeking information on the use of data processing in libraries and the mechanization of routine library processes and procedures.  I would like descriptions of both general and specific applications of automation in such areas as circulation, cataloging, acquisitions, serial records, and other record-keeping.  Examples should be based on the operation of a conventional public or university library, or practices in a special library which could also be applied in a public or university library.  Give descriptions of equipment and operations, both present and projected.\n",
            "Score:  111.96946592969906\n",
            "Document:  [\"University Library Administration Rogers, R.D. A university library is both a collegiate library and a research library. It is collegiate in its provision of books and other documentary records to support the students' program of instruction and to encourage the habit of reading and the use of libraries.  As does the college library, the university library must also provide materials for use by the faculty members in the preparation of their courses of instruction and by the staff of the institution in the performance of their administrative responsibilities. However, the university library differs from the college library in offering a wider range of undergraduate programs, offering graduate instruction beyond the Master's level, and usually offering advanced professional programs in a number of fields. \"]\n",
            "Query: Is there any established means at present for an international exchange of material about information retrieval?  If there is, does it take the form of an international agency or center which regularly distributes information retrieval methods and research results?  If there is not, in what ways has this material crossed national boundaries?  What seem to have been some of the problems blocking a better international exchange, and is any effort being made to solve some of those problems?\n",
            "Score:  82.31968388741016\n",
            "Document:  [\"Analysis and Organization of Knowledge for Retrieval Farradane, J.E.L. In a university, the mode of research is usually what is called 'pure' or 'basic' research; since I am keeping in mind primarily the applications of information science, I will prefer the word 'basic', although there is not so much difference.  In such research, and really in any good research, one should not be collecting data haphazardly.  One must isolate and define a problem and, as far as possible, control other conditions so that interfering factors are eliminated.  Preferably one will narrow down the problem to manageable proportions.  It is then essential to approach the problem with some sort of hypothesis or theory of the situation, and to concentrate on obtaining evidence for or against that hypothesis.  The important task is to devise just that crucial experiment which will give the answer as efficiently as possible. If the answer disproves the hypothesis, one has at least further evidence upon which to construct a different hypothesis; if it confirms the hypothesis, one is ready for a further step forward, and so on.  Research is easier in a fully controlled and reproducible situation; in a biological or human situation one must often have recourse to statistical methods, but this does not alter the general methodology.  On the whole, I find a clear methodology lacking in much that is being done in the field of information science today. \"]\n",
            "Query: Information retrieval is still such a new and experimental field that a line distinguishing research and practice is often difficult - even impossible - to draw.  Are there, however, actual centers of research on information retrieval?  If so, in which countries are they located?  Who supports them - government, business, universities, or libraries?  Can information retrieval as a specialized research discipline be said to be emerging, or is it still an amalgam of skills from other fields, such as mathematics, engineering, and library science?  In other words, tell me about information retrieval research.\n",
            "Score:  87.70508254807123\n",
            "Document:  [\"A Guide to the Construction and Use of Special Schemes Vickery, B.C. The use of classification in libraries is traditional and its value is appreciated.  For documentation and information retrieval in general, other techniques such as alphabetical indexing and machine selection are also available.  That classification is of value in information retrieval as well as in book arrangement is, however, made evident in two ways.  First, to achieve consistency and subtlety in alphabetical indexing and machine selection designers of such retrieval systems find the need to introduce classificatory techniques.  Second, there is a continuing demand for the construction of special classifications for detailed arrangement and cataloguing of documents in restricted but intensively cultivated fields of knowledge. It is to help meet these demands, particularly the second, that this guide has been prepared.  The techniques of detailed depth classification have been greatly developed during the past decade, and instruments of much greater subtlety and efficiency than the traditional 'tree-of-knowledge' schemes can now be designed. These developments have been reported mainly as research papers in a variety of library journals and are often made unnecessarily difficult to follow by the use of unfamiliar terminology. There is a need for a more simply written and more readily available practical guide to the use of the newer techniques of classification. \"]\n",
            "Query: Most resources have been spent on applying information retrieval techniques to the physical and medical sciences.  But, has information retrieval been used at all in the natural sciences, social sciences, and humanities?  If so, what have been some of the problems which have been encountered with these subject areas and how have they been solved, if at all?  Have the characteristics of these subject areas necessitated the development of new information retrieval techniques? What are the prospcts for future machine control in these areas?\n",
            "Score:  95.95109008035335\n",
            "Document:  [\"Bibliographical Statistics as a Guide to Growth Points in Science Meadows, A.J. O'connor, J.G. Efforts have been made in recent years to use statistical studies of scientific research papers as a means for deriving general statements about trends in science.  For example, there has been a continuing interest in the question of how the frequency of citation of a scientific paper depends on its age.  These investigations have, however, been mainly concerned with the major branches of science only, and have also, perhaps, been rather more interested in identifying past trends than in making specific predictions for the future. Although such results are obviously valuable, it is also important to push these analyses further into smaller areas within a main scientific subject division, since such areas may have significantly different bibliographical properties from the subject average.  One particularly important aspect of such work concerns the origin of new growth areas within a major discipline. We can specifically pose the question: is it possible, purely from a statistical analysis of scientific research papers, to identify the appearance of a new growth area and, if so, how soon after its first appearance can such an area be identified? \"]\n",
            "Query: Is there any use for traditional classification schemes - DDC, UDC, LC, etc. - in information retrieval systems?  If there is, which scheme appears most suited to machine use and where has it been applied? If there is not, why are these classification schemes irrelevant? Has research shown that a subject classification of knowledge is completely unnecessary in machine systems? Or, have new schemes been devised which appear to be more suited to machine use?\n",
            "Score:  101.72675308158477\n",
            "Document:  [\"A Guide to the Construction and Use of Special Schemes Vickery, B.C. The use of classification in libraries is traditional and its value is appreciated.  For documentation and information retrieval in general, other techniques such as alphabetical indexing and machine selection are also available.  That classification is of value in information retrieval as well as in book arrangement is, however, made evident in two ways.  First, to achieve consistency and subtlety in alphabetical indexing and machine selection designers of such retrieval systems find the need to introduce classificatory techniques.  Second, there is a continuing demand for the construction of special classifications for detailed arrangement and cataloguing of documents in restricted but intensively cultivated fields of knowledge. It is to help meet these demands, particularly the second, that this guide has been prepared.  The techniques of detailed depth classification have been greatly developed during the past decade, and instruments of much greater subtlety and efficiency than the traditional 'tree-of-knowledge' schemes can now be designed. These developments have been reported mainly as research papers in a variety of library journals and are often made unnecessarily difficult to follow by the use of unfamiliar terminology. There is a need for a more simply written and more readily available practical guide to the use of the newer techniques of classification. \"]\n",
            "Query: Coordinate indexing utilizes descriptors for controlled language.  Of what use are descriptors in the construction of an index?  How can descriptors be used for searching in an information retrieval system?\n",
            "Score:  50.88117857936552\n",
            "Document:  ['Russian descriptor informatics dictionary Chernyi, A.I. This dictionary contains general alphabetical list of descriptors and synonymous, keywords, and word combinations. It is intended for use in coordinating the indexing of documents. ']\n",
            "Query: What are the characteristics of MEDLARS (Medical Literature Analysis and Retrieval System) project which has been undertaken by the National Library of Medicine?  How does it index current medical journals and of what relation is this indexing system to Index Medicus? What are the major components of the MEDLARS project and its major operating details?\n",
            "Score:  92.97187036620782\n",
            "Document:  [\"MEDLARS:  A Summary Review and Evaluation of Three Reports Stevens, N.D. The MEDLARS (Medical Literature Analysis and Retrieval System) system at the National Library of Medicine (NLM) has over the past few years been one of the most significant and one of the most publicized automated bibliographic information retrieval systems.  Over two hundred articles on it have appeared in American newspapers and popular magazines, in specialized medical journals throughout the world, and in a variety of library journals.  The publicity that has attended this project has, in a way, been unfortunate, for it has presented an exaggerated picture of the system and its accomplishments which has only made the sceptics more skeptical; and it has obscured in part the examination of MEDLARS' real accomplishments.  There has to date been very little careful outside analysis and evaluation of MEDLARS.  Over 50 percent of all the articles listed in the bibliography in Austin's report, and virtually all the substantive ones, represent the work of persons closely connected with NLM or the development of the MEDLARS system.  Their judgement on the effectiveness of the system and its overall value cannot help but be colored by this connection. \"]\n",
            "Query: How can the computer be used in medical science for diagnostic and clinical record keeping purposes?  Have any programs of automation been tried in hospitals?  If so, what have been the results? What problems have been encountered in the use of automation in medicine?  For what purposes can an automated system of clinical records be used?  What are other possible uses of the computer in medicine?\n",
            "Score:  87.53245959037906\n",
            "Document:  [\"Economic Analysis of the Public Libraries Newhouse, J.P. This study addresses itself to several questions important to all public libraries.  How should the library allocate its book budget?  What kinds of books should it tend to buy?  What types of households use the library?  Why do some households not use the library?  What is the cost of the various services provided by the library?  What specific steps can the library take to improve its services?  What are the library's options in choosing among the different circulation systems?  For how long should the library allow books to be checked out?  How frequently should overdue notices be sent out?  Is an investment in a security system worthwhile? We have studied these questions in the context of one public library - the Beverly Hills (California) Public Library - and have developed a methodology for determining answers to them, as well as to other questions that arose during our investigation.  Although answers will vary from library to library, our methodology is quite general and should prove useful at many public libraries. \"]\n",
            "Query: What is the effect on librarians of automation?  Note the new types of technology to be used in the library which will have an effect on the status, position, and function of the librarians.  What changes are being contemplated or have been initiated to introduce automation into the education of librarians?\n",
            "Score:  75.85893483994707\n",
            "Document:  [\"Economic Analysis of the Public Libraries Newhouse, J.P. This study addresses itself to several questions important to all public libraries.  How should the library allocate its book budget?  What kinds of books should it tend to buy?  What types of households use the library?  Why do some households not use the library?  What is the cost of the various services provided by the library?  What specific steps can the library take to improve its services?  What are the library's options in choosing among the different circulation systems?  For how long should the library allow books to be checked out?  How frequently should overdue notices be sent out?  Is an investment in a security system worthwhile? We have studied these questions in the context of one public library - the Beverly Hills (California) Public Library - and have developed a methodology for determining answers to them, as well as to other questions that arose during our investigation.  Although answers will vary from library to library, our methodology is quite general and should prove useful at many public libraries. \"]\n",
            "Query: What are the aims and objectives of the medical literature analysis and retrieval system (MEDLARS)?  How does MEDLARS operate?  What are the possible applications of MEDLARS to future information retrieval systems?\n",
            "Score:  61.793881105977285\n",
            "Document:  ['MEDLARS 1963-1967 Austin, C.J. The purpose of this document is to present a final description of the system as it has evolved through a period of four years of operation.  This will add the final chapter to the present MEDLARS story at a time when the Library is on the threshold of developing an entirely new system, utilizing the latest techniques of documentation and information science coupled with modern, \"third- generation\" computer equipment. The reader interested in a complete chronicle of the Library\\'s experience with MEDLARS is advised to combine the reading of this report with a re-reading of the original MEDLARS story.  Thus he will be able to develop a complete picture that answers the questions: (1) What did the Library set out to do? (2) What was actually accomplished? and (3) What changes were made in the original system design and why? ']\n",
            "Query: The standard method of finding information in today's libraries is through the use of the alphabetically arranged card catalog or the classified catalog based on a classification system such as the DC or LC.  Can these systems be modified for use with automated information retrieval?\n",
            "Score:  59.41312778284172\n",
            "Document:  ['User Requirements in Identifying Desired Works in Large Libraries Lipetz, B.A. The work reported here is a study of the utilization of the card catalog of a very large library, specifically the principal catalog of the library system of Yale University. The study was motivated by two basic concerns, one of them of a long-term, or exploratory, nature, the other of a short-term, or operationally supportive, nature.  The long-term concern is the question of how to design a computerized catalog for a very large library that can be expected to give the best possible performance.  The short-term concern is the question of whether, and, of so, how, existing card catalogs in very large libraries may be made more responsive to user requirements.  It was recognized that a carefully designed study of actual utilization of a catalog of a large library could shed useful light in both areas of concern. ']\n",
            "Query: In catalogs which are either arranged alphabetically or arranged by classification number, the LC entry, printed in readable language, is ultimately important because the individual looking for information has a definite author, title, or subject phrase in his language (probably English in our case) in mind.  Will LC entries and subject headings be used in the same manner in automated systems?\n",
            "Score:  70.07977954674524\n",
            "Document:  ['Prejudices and Antipathies: A tract on the LC subject heads concerning people Berman, S. Since the first edition of Library of Congress subject headings appeared 60 years ago, American and other libraries have increasingly relied on this list as the chief authority -- if not the sole basis -- for subject cataloging.  There can be no quarrel about the practical necessity for such a labor-saving, worry-reducing work, nor--abstractly--about its value as a global standardizing agent, a means for achieving some uniformity in an area that would otherwise be chaotic. Undoubtedly, it is a real boon to scholars, as well as to ordinary readers, to find familiar, fairly constant headings in subject catalogs as far removed geographically as Washington, DC and Lusaka, Zambia.  Knowledge and scholarship are, after all, universal.  And a subject-scheme should, ideally, manage to encompass all the facets of what has been printed and subsequently collected in libraries to the satisfaction of the worldwide reading community.  Should, that is.  But in the realm of headings that deal with people and cultures--in short, with humanity--the LC list can only \"satisfy\" parochial, jingoistic Europeans and North Americans, white-hued, at least nominally Christian (and preferably Protestant) in faith, comfortably situated in the middle and higher-income brackets, largely domiciled in suburbia, fundamentally loyal to the Established Order, and heavily imbued with the transcendent, incomparable glory of Western civilization.  Further, it reflects a host of untenable--indeed, obsolete and arrogant--assumptions with respect to young people and women.  And exudes something less than sympathy or even fairness toward organized labor and the sexually unorthodox or \"avant-garde.\" ']\n",
            "Query: Bibliographic control before and after MARC is reviewed.  The capability of keying into online systems brought an interdependence among libraries, the service centers that mediate between them, and the large utilities that process and distribute data.  From this has developed the basic network structure among libraries in the United States.  The independent development of major networks has brought problems in standardization and coordination. The authors point out that while technology has led toward centralization of automated library services, new developments are now pushing toward decentralization.  Coordination is a requirement to avoid fragmentation in this new environment.\n",
            "Score:  111.50307452813256\n",
            "Document:  ['Information Network Prospects in the United States Becker, J. Unmistakable signs are pointing the way toward the creation sometime soon of a national information network in the United States.  The concept of a national network implies the interconnection of existing information systems and libraries through communications.  Certainly one of the great strengths of this nation is the great array of intellectual, scholarly, and research resources to be found in its libraries and information centers. Without integration and close cooperation, however, these resources will remain a series of separate, insulated institutions.  But if maximum communication can be established among them, this array can be converted into a national resource of immense value to citizens throughout the country. ']\n",
            "Query: The retrieval performance of book indexes can be measured in terms of their ability to direct a user selectively to text material whose identity but not location is known.  The method requires human searchers to base their searching strategies on actual passages from the book rather than on test queries, natural or contrived.  It circumvents the need for relevance judgement, but still yields performance indicators that correspond approximately to the recall and precision ratios of large document retrieval system evaluation.  A preliminary application of the method to the subject indexing of two major encyclopedias showed one encyclopedia apparently superior in both the finding and discrimination abilities of retrieval performance.  The method is presently best suited for comparative testing since its ability to yield absolute or reproducible measures is as yet not established.\n",
            "Score:  143.26888007274417\n",
            "Document:  ['Performance and Cost of \"Free-Text\" Search systems Kent, A.K. The purpose of an information-retrieval system is to provide the user with citations relevant to his query.  Since the user is the only person competent to make the final judgement of relevance it is natural to suppose that the selection of items from a data base will lead to two kinds of retrieval error.  The extent of these errors is expressed by the familiar measures of performance, precision and recall.  Precision measures the failure of the system to retrieve only relevant documents while recall measures its failure to retrieve all relevant documents actually present in the data base.  It is difficult to visualize a situation in which a user would find advantage in being provided with irrelevant citations.  From the user\\'s point of view, therefore, a system which offers less than 100 per cent precision is a deficient system. ']\n",
            "Query: A linkage similarity measure which takes into account both the bibliographic coupling of documents and their cocitations (both cited and citing papers) produced improved document retrieval over a measure based only on bibliographic coupling.  The test collection consisted of 1712 papers whose relevance to specific queries had been judged by users.  To evaluate the effect of using cocitation data, we calculated for each query two measures of similarity between each relevant paper and every other paper retrieved. Papers were then sorted by the similarity measures, producing two ordered lists.  We then compared the resulting predictions of relevance, partial relevance, and non-relevance to the user's evaluations of the same papers. Overall, the change from the bibliographic coupling measure to the linkage similarity measure, representing the introduction of cocitation data, resulted in better retrieval performance.\n",
            "Score:  150.4579065455289\n",
            "Document:  [\"The Structure of Scientific Literatures II: Toward a Macro- and Microstructure for Science Griffith, B.C. Small, H.G. Stonehill, J.A. Dey, S. Part I of this paper described the first steps in mapping the scientific literature, using a new technique - co-citation - to measure the degree of similarity among documents.  The work developed directly from an earlier paper which defined this measure, and explored its relationship to other citation measures for identifying relationships among documents.  We now report the outcome of an attempt to create 'maps' of the scientific literature. The scales of these maps have been systematically manipulated so that they present, not only an overview of all highly-cited papers in natural science, but also a detailed view of a single scientific specialty.  At each level we have systematically sought indications of the validity of the mapping operation, and have indications that the maps display at least certain important aspects of the specialty structure of science. \"]\n",
            "Query: The way that individuals construct and modify search queries on a large interactive document retrieval system is subject to systematic biases similar to those that have been demonstrated in experiments on judgements under uncertainty.  These biases are shared by both naive and sophisticated subjects and cause the inquirer searching for documents on a large interactive system to construct and modify queries inefficiently.  A searching algorithm is suggested that helps the inquirer to avoid the effect of these biases.\n",
            "Score:  91.42991211133405\n",
            "Document:  ['An Evaluation of Query Expansion by the Addition of Clustered Terms for a Document Retrieval System Minker, Jack Wilson, Gerald A. Zimmerman, Barbara H. An evaluation of graph theoretical clusters of index terms which can be extracted from an automatically indexed document collection, and the effects of employing such cluster in automatic document retrieval is described.. The graph theoretical cluster which were developed from six data base under two different cluster definition were analyzed for average size and related data.. The clusters were also used to expand the queries in each of six data bases to determine the effect of the expansions on the document retrieval results.. Although a large variety of clusters and associated query explanations were obtained, no significant improvements in the document retrieval performance were achieved.. In some cases, however, significant degradations in the retrieval performance occurred.. Although seemingly meaningful clusters can be obtained, the results indicate that the effort involved in finding clusters and adding the clustered terms to queries is far to great to warrant their use in an operational system.. The data bases employed were relatively small, and the  authors caution against generalizing these results to large data bases or other  situations.. ']\n",
            "Query: This article concerns the problem of how to permit a patron to represent the relative importance of various index terms in a Boolean request while retaining the desirable properties of a Boolean system. The character of classical Boolean systems is reviewed and related to the notion of fuzzy sets.  The fuzzy set concept then forms the basis of the concept of a fuzzy request in which weights are assigned to index terms. Ther properties of such a system are discussed, and it is shown that such systems retain the manipulability of traditional Boolean requests.\n",
            "Score:  153.99086353071698\n",
            "Document:  ['Fuzzy Sets Zaden, L. A. A fuzzy set is a class of objects with a continuum of grades of membership.. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one.. The notions of inclusion, union, intersection, complement, relation, convexity, etc., are extended to such sets, and various properties of these notions in the context of fuzzy sets are established.. In particular, a separation theorem for convex fuzzy sets is proved without requiring that the fuzzy sets be disjoint.. ']\n",
            "Query: A commercially available online search was used as a standard for comparative searching and evaluation of an in-house information system based on automatic indexing.  System features were identified and evaluated on the basis of their usefulness in various kinds of searching, their ease in implementation, and how they are influenced by differences in user type or specific applications.  Some common features of the commercial system, such as online instruction, user-specified print formats, dictionary display, and truncation, are seen to be unnecessary or impractical for the in-house system.  In designing the in-house system, therefore, detald consideration must be given to the applications, operating environment, and real user needs.  While a commercial system can serve as a useful standard for comparative evaluation, one must be careful not to attempt to duplicate it blindly in-house.\n",
            "Score:  127.32390397895217\n",
            "Document:  ['The Theoretical Foundation of the IDC-system: Six Postulates for Information Retrieval Fugmann, Robert Successful delegated searching for publications relevant to the topic of an inquirer obeys rules whose relations to thermodynamics are unmistakable. By the continuous growth of a documentation system in the physical and conceptual respect, steadily increasing demands are made on the degree of order which prevails in the system or can be established at the specific request of an inquirer.  If the order in a system cannot keep pace with the increasing requirements, its working capability will continuously decrease, because the searcher is becoming more and more overburdened in relation to his available search time, search patience, and search memory.  The degree of order attainable in a growing literature collection can be estimated on the basis of six postulates.  The better the requirements imposed by these postulates are approximated in a practical documentation system, the higher are its working capability and life expectancy, but the expenditure to be made on the literature analyses must also inevitably be higher. The establishment of these postulates originated from practical experience with the IDC-system and its precursors.  These postulates form the basis of this system and of its further development. ']\n",
            "Query: It is argued that in information science we have to distinguish physical, objective, or document space from perspective, subjective, or information space.  These two spaces are like maps and landscapes: each is a systematic distortion of the other.  However, transformation can be easily made once the two spaces are distinguished.  If the transformations are omitted we only get unhelpful physical solutions to information problems.\n",
            "Score:  71.94671039860596\n",
            "Document:  ['Communication among Scientists and Engineers Nelson, C. E. In the course of collecting data on nine scientific and technological disciplines, it has become obvious to us that in their communication activities, some disciplines behave quite differently from others.. Recently, we have reanalyzed our data for the physical, the engineering, and the social sciences.. We do not have time to discuss differences among all three groups, so we have decided to compare only the physical and social sciences.. We have included data pertaining to the engineering sciences on the graphs, however, so you can get some idea of how they differ from the other two groups.. Before discussing these differences, we should like to emphasize that there are similarities, that there are of major importance, and that they, in fact, make genuine comparisons among the groups feasible.. We will discuss differences between the physical and the social sciences in terms of three major communication characteristics associated with science.. ']\n",
            "Query: The use of document clusters has been suggested as an efficient file organization for a document retrieval system.  It is possible that by using this information about the relationships between documents that the effectiveness of the system (i.e., its ability to distinguish relevant from non-relevant documents) may also be improved.  In this paper a probabilistic model of cluster searching  based on query classification is described.  This model is tested with retrieval experiments which indicate that it can be more effective than heuristic cluster searches and cluster searches based on other models.  It can also be more effective than a full search in which every document is compared to the query.  The efficiency aspects of the implementation of the model are discussed.\n",
            "Score:  156.69530241478734\n",
            "Document:  ['An Evaluation of Query Expansion by the Addition of Clustered Terms for a Document Retrieval System Minker, Jack Wilson, Gerald A. Zimmerman, Barbara H. An evaluation of graph theoretical clusters of index terms which can be extracted from an automatically indexed document collection, and the effects of employing such cluster in automatic document retrieval is described.. The graph theoretical cluster which were developed from six data base under two different cluster definition were analyzed for average size and related data.. The clusters were also used to expand the queries in each of six data bases to determine the effect of the expansions on the document retrieval results.. Although a large variety of clusters and associated query explanations were obtained, no significant improvements in the document retrieval performance were achieved.. In some cases, however, significant degradations in the retrieval performance occurred.. Although seemingly meaningful clusters can be obtained, the results indicate that the effort involved in finding clusters and adding the clustered terms to queries is far to great to warrant their use in an operational system.. The data bases employed were relatively small, and the  authors caution against generalizing these results to large data bases or other  situations.. ']\n",
            "Query: Current online library network technology is described, including the physical and functional aspects of networks.  Three types of networks are distinguished:  search service (e.g., SDC, Lockheed), customized service that provide bibliographic files (e.g., OCLC, Inc., RLIN), and service center (e.g., NELINET, INCOLSA).  It is predicted that as technology evolves more services will be provided outside the library directly to the user through his home or office.\n",
            "Score:  79.27280306244798\n",
            "Document:  ['A Campus-Based Information Center Carmon, J.L. Several features of the University of Georgia Information Dissemination Center, including current awareness, or SDI, and retrospective search services, the information specialists who provide the interface between the user and the computer system, and an experimental network linking individual centers, are discussed.  A survey which assessed the impact of the services on the information habits of the university users is also discussed.  Over 97% of the survey respondees indicated that the services had contributed to their professional activities.  Some users reported that the service had been a method of bypassing library reference works; others indicated that the service had brought them back into the  library and made them aware of information sources previously unknown to them. ']\n",
            "Query: An experimental computer program has been developed to classify documents according to the 80 sections and five major section groupings of Chemical Abstracts (CA).  The program uses pattern recognition techniques supplemented by heuristics.  During the \"training\" phase, words from pre-classified documents are selected, and the probability of occurrence of each word in each section of CA is computed and stored in a reference dictionary.  The \"classification\" phase matches each word of a document title against the dictionary and assigns a section number to the document using weights derived from the probabilities in the dictionary.  Heuristic techniques are used to normalize word variants such as plurals, past tenses, and gerunds in both the training phase and the classification phase.  The dictionary lookup technique is supplemented by the analysis of chemical nomenclature terms into their component word roots to influence the section to which the documents are assigned.  Program performance and human consistency have been evaluated by comparing the program results against the published sections of CA and by conducting an experiment with people experienced in the assignment of documents to CA sections.  The program assigned approximately 78% of the documents to the correct major section groupings of CA and 67% of the correct sections or cross-references at a rate of 100 documents per second.\n",
            "Score:  280.70492132075043\n",
            "Document:  ['The CA Integrated Subject File.  II. Evaluation of Alternative Data Base Organizations Zipperer, W.C. Park, M.K. Carmon, J.L. The relative retrieval performances of the CA Integrated Subject File (CAISF), CA Condensates, and a Merged File created from these two data bases have been measured.  Retrieval performance is reported in terms of recall and precision values as well as costs.  The precision and recall retrieval failures - i.e., irrelevant documents and missed documents - have been analyzed for each data base and characterized according to the five major types of failures: index language, indexing, searching, clerical, and miscellaneous.  Over-all analysis of the performance suggests that an effective data base can be created by augmenting the CA Condensates data base with Registry Numbers and some representation of the CAISF General Subject concept headings, which results in a file approximately half the size of the corresponding CAISF data base and is suitable for search using existing retrieval system software. ']\n",
            "Query: Some of the automatic classification procedures used in information retrieval derive clusters of documents from an intermediate similarity matrix, the computation of which involves comparing each of the documents in the collection with all of the others.  It has recently been suggested that many of these comparisons, specifically those between documents having no terms in common, may be avoided by means of the uyse of an inverted file to the document collection.  This communication shows that the approach will effect reductions in the number of interdocument comparisons only if the documents are each indexed by a limited number of indexing terms; if exhaustive indexing is used, many document pairs will be compared several times over and the computation will be greater than when conventional approaches are used to generate the similarity matrix.\n",
            "Score:  162.2066759391583\n",
            "Document:  ['The Association Factor in Information Retrieval Stiles, H. Edmund This paper describes an all computer document retrieval system which can find documents related to a request even though they may not be indexed by the exact terms of the request, and can present these documents in the order of their relevance to the request.. The key to this ability lies in the application of a statistical formula by which the computer calculates the degree of association between pairs of index terms.. With proper manipulation of these associations (entirely within the machine) a vocabulary of synonyms, near synonyms and other words closely related to any given term or group of terms is derived.. Such a vocabulary related to a group of request terms is believed to be a much more powerful tool for selecting documents from a collection than has been available heretofore.. By noting the number of matching terms between this extended list of request terms and the terms used to index a document, and with due regard for their degree of association, documents are selected by the computer and arranged in the order of their relevance to the request.. ']\n",
            "Query: The Use of a minicomputer in various phases of creating the thesaurus for the National Information Center for Special Education Materials (NICSEM) database is described.  The minicomputer is used to collect, edit, and correct candidate thesaurus terms.  The use of the minicomputer eases the process of grouping terms into files of similar concepts and facilitates the generation of products useful in vocabulary review and in term structuring.  Syndetic relations, indicated by assigning coded identification numbers, are altered easily in the design phase to reflect restructuring requirements.  Because thesaurus terms are already in machine- readable form, it is simple to prepare print programs to provide permuted, alphabetic, hierarchical, and chart formatted term displays.  Overall, the use of the minicomputer facilitates initial thesaurus entry development by reducing clerical effort, editorial staff decisions, and overall processing times.\n",
            "Score:  167.43746983082522\n",
            "Document:  ['Automatic Construction of Thesauri and of Concept Systems for Dictionaries and Subject Lists Lang, F.H. After a synopsis of the relations existing between descriptors and their concepts, the EPD-program called \"GENTHES\" is described.  The program supports the construction of a thesaurus and its use.  The relational system corresponds to ISO/DIS 2788 (UNESCO) and DIN 1463.  It differentiates, however, in addition generically related and contiguous terms pertaining to a part-whole system. Characteristics that determine narrower terms against their broader terms are introduced as new relation.  Many types of associations are made available for experimenting.  The programmed generation of dependent relations reduces the amount of work to one third although ensuring total avoidance of formal errors and logical contradictions, even in applying permitted polyhierarchy.  The program is available in batch mode or in an interactive timesharing version (Remote GENTHES).  The program functions are input, logical and formal input checking, generation of relations, display, delete, print on line printer and storage on disk.  GENTHES is running in Vienna on a System IBM/370. ']\n",
            "Query: Decision Support Systems (DSS) represent a concept of the role of computers within the decision making process.  The term has become a rallying cry for researchers, practitioners, and managers concerned that Management Science and Management Information Systems fields have become unnecessarily narrow in focus.  As with many rallying cries, the term is not well defined.  For some writers, DSS simply mean interactive systems for use by managers.  To others, the key issue is support, rather than system.  They focus on understanding and improving the decision process; a DSS is then designed using any available and suitable technology. Some researchers view DSS as a subfield of MIS, while others regard it as an extension of Management Science techniques.  The former define Decision Support as providing managers with access to data and the latter as giving them access to analytic models.  The key argument of this paper is that the term DSS is relevant to situations where a \"final\" system can be developed only through an adaptive process of learning and evolution.  The design strategy must then focus on getting finished; this is very different from Management Science and Data Processing approaches.  The research issued for DSS center around adaption and evolution; they include managerial learning representation of tasks and user behavior, design architecture and strategies for getting started.\n",
            "Score:  211.1936612208637\n",
            "Document:  ['Management Misinformation Systems Ackoff, R.L. Five assumptions commonly made by designers of management information systems are identified.  It is argued that these are not justified in many (if not most) cases and hence lead to major deficiencies in the resulting systems. These assumptions are: (1) the critical deficiency under which most managers operate is the lack of relevant information, (2) the manager needs the information he wants, (3) if a manager has the information he needs his decision making will improve, (4) better communication between managers improves organizational performance, and (5) a manager does not have to understand how his information system works, only how to use it.  To overcome these assumptions and the deficiencies which result from them, a management information system should be imbedded in a management control system. A procedure for designing such a system is proposed and an example is given of the type of control system which it produces. ']\n",
            "Query: A new method is described to extract significant phrases in the title and the abstreact of scientific or technical documents.  The method is based upon a text structure analysis and uses a relatively small dictionary. The dictionary has been constructed based on the knowledge about concepts in the field of science or technology and some lexical knowledge.  For significant phrases and their component items may be used in different meanings among the fields.  A text analysius approach has been applied to select significant phrases as substantial and semantic information carriers of the contents of the abstract.  The results of the experiment for five sets of documents have shown that the significant phrases are effectively extracted in all cases, and the number of them for every document and the processing time is fairly satisfactory.  The information representation of the document, partly using the method, is discussed with relation to the construction of the document information retrieval system.\n",
            "Score:  209.84911859690487\n",
            "Document:  [\"Some Aspects of Developing and Studying a Descriptor Information Language for General Technology Shemakin, Yu. I. The methods and results of an endeavor to develop an information retrieval language for automatic retrieval systems meant for handling a polytechnical document collection are described.. The descriptor dictionary includes general and special terms, both single-word and phrase terms, which is conducive to higher recall and relevance; it comprises a classified index and a lexico-semantic index as well as tables of generic relations.. The size of the dictionary is 5,542 descriptors and 3,073 keywords.. The indexing procedure includes:  analysis of document content and its characterization by keywords elicited from natural text; and creation of the search pattern using the descriptor dictionary.. The techniques are described which are applied to analyze the documents into semantic aspects that constitute the elements of the formalized model of a document's condensed content.. The procedure employed to translate a text into the retrieval language comprises selection of words both from the title and the body of the document.. Main principles for retrieval efficiency determination using mathematical-statistic methods are given.. Tests on multi-subject collections show a probability of 85-% recall and 70-% relevance at a standard deviation of 25%.. These findings have been corroborated by the results of the basic experiment on a file of up to 2,500 search patterns using 42 requests..  Among the factors of losses there are the poor quality of abstracts (into cards) and the absence of a single abstracting procedure; it is proposed that abstractors should be in future charged with writing abstracts in keywords and, ultimately, in the descriptor language.. The experimental results attest to the feasibility and practical sensibility of creating a multi-disciplinary information retrieval system to be based on a broad-scope descriptor dictionary and on the suggested methods for document and request indexing.. \"]\n",
            "Query: Passage retrieval (already operational for lawyers) has advantages in output form opver references retrieval and is economically feasible. Previous experiments in passage retrieval for scientists have demonstrated recall and false retrieval rates as good or better than those of present reference retrieval services.  The present experiment involved a greater variety of forms of retrieval question.  In addition, search words were selected independently by two different people for each retrieval question. The search words selected, in combination with the computer procedures used for passage retrieval, produced average recall ratios of 72 and 67%, respectively, for the two selectors.  The false retrieval rates were (except for one predictably difficult question) respectively 13 and 10 falsely retrieved sentences per answer-paper retrieved.\n",
            "Score:  148.91960956228934\n",
            "Document:  ['Text Searching Retrieval of Answer-Sentences and Other Answer-Passages O\\'Connor, John Some new text searching retrieval techniques are described which retrieve not documents but sentences from documents and sometimes (on occasions determined by the computer) multi-sentence sequences.. Since the goal of the techniques is retrieval of answer-providing documents, \"answer-passages\" are retrieved.. An \"answer-passage\" is a passage which is either answer-providing or \"answer-indicative,\" i.e., it permits inferring that the document containing it is answer-providing.. In most cases answer-sentences, i.e., single-sentence answer-passages, are retrieved.. This has great advantages for screening retrieval output.. Two new automatic procedures for measuring closeness of relation between clue words in a sentence are described.. One approximates syntactic closeness by counting the number of intervening \"syntactic joints\" (roughly speaking, prepositions, conjunctions and punctuation marks) between successive clue words.. The other measure uses word proximity in a new way.. The two measures perform about equally well.. The computer uses \"enclosure\" and \"connector words\" for determining when a multi-sentence passage should be retrieved.. However, no procedure was found in this study for retrieving multi-paragraph answer-passages, which were the only answer-passages occurring in 6% of the papers.. In a test of the techniques they failed to retrieve two answer-providing documents (7% of those to be retrieved) because of one multi-paragraph answer-passage and one complete failure of clue word selection.. For the other answer-providing documents they retrieved at all recall levels with greater precision than SMART, which has produced the best previously reported recall-precision results.. The retrieval questions (mostly from real users) and documents used in this study were from the field of information science.. The results of the study are surprisingly good for retrieval in such a \"soft science,\" and it is reasonable to hope that in less \"soft\" sciences and technologies the techniques described will work even better.. On this basis a dissemination and retrieval system of the near future is predicted.. ']\n",
            "Query: In this paper we describe a practical method of partial-match retrieval in very large data files.  A binary code word, called a descriptor, is associated with each record of the file.  These record descriptors are then used to form a derived descriptor for a block of several records, which will serve as an index for the block as a whole; hence, the name \"indexed descriptor files.\"  First the structure of these files is described and a simple, efficient retrieval algorithm is presented.  Then its expected behavior, in terms of storage accesses, is analyzed in detail.  Two different file creation procedures are sketched, and a number of ways in which the file organization can be \"tuned\" to a particular application is suggested.\n",
            "Score:  152.88847352581882\n",
            "Document:  [\"Some Aspects of Developing and Studying a Descriptor Information Language for General Technology Shemakin, Yu. I. The methods and results of an endeavor to develop an information retrieval language for automatic retrieval systems meant for handling a polytechnical document collection are described.. The descriptor dictionary includes general and special terms, both single-word and phrase terms, which is conducive to higher recall and relevance; it comprises a classified index and a lexico-semantic index as well as tables of generic relations.. The size of the dictionary is 5,542 descriptors and 3,073 keywords.. The indexing procedure includes:  analysis of document content and its characterization by keywords elicited from natural text; and creation of the search pattern using the descriptor dictionary.. The techniques are described which are applied to analyze the documents into semantic aspects that constitute the elements of the formalized model of a document's condensed content.. The procedure employed to translate a text into the retrieval language comprises selection of words both from the title and the body of the document.. Main principles for retrieval efficiency determination using mathematical-statistic methods are given.. Tests on multi-subject collections show a probability of 85-% recall and 70-% relevance at a standard deviation of 25%.. These findings have been corroborated by the results of the basic experiment on a file of up to 2,500 search patterns using 42 requests..  Among the factors of losses there are the poor quality of abstracts (into cards) and the absence of a single abstracting procedure; it is proposed that abstractors should be in future charged with writing abstracts in keywords and, ultimately, in the descriptor language.. The experimental results attest to the feasibility and practical sensibility of creating a multi-disciplinary information retrieval system to be based on a broad-scope descriptor dictionary and on the suggested methods for document and request indexing.. \"]\n",
            "Query: Recenty technological advances and the success of OCLC, Inc. has led to the emergence of three additional nonprofit library networks:  the Research Libraries Information Network (RLIN) of the Research Libraries Group, Inc., the University of Toronto Library Automation System (UTLAS), and the Washington Library Network (WLN).  This paper examines the economic and technological factors affecting the evolution of these networks and also explores the role of those state and regional (multistate) networks that broker OCLC services.  The competitive and cooperative nature of network relationships is a major theme of the discussion.\n",
            "Score:  142.14747955053517\n",
            "Document:  [\"A Regional Medical Library Network Pizer, Irwin H. The raison d'etre for cooperative networks is discussed, and the development of the SUNY Biomedical Communication Network is traces briefly; a description of the system and its products is given.. The cooperative cataloging program engaged in with the Francis A. Countway Library of Medicine and the National Library of Medicine is described, as are the efforts of the Network in the production of regional and state-wide union lists of serials.. \"]\n",
            "Query: A new type of natural language parser is presented.  The idea behind this parser is to map input sentences into the deepest form of the representation of their meaning and inferences, as is appropriate.  The parser is not distinct from an entire understanding system.  It uses an integrated conception of inferences, scripts, plans and other knowledge to aid in the parse.  Furthermore, it does not attempt to parse everything it sees.  Rather, it determines what is most interesting and concentrates on that, ignoring the rest.\n",
            "Score:  102.29731330286481\n",
            "Document:  ['The Teachable Language Comprehender: A Simulation Program and Theory of Language Quillian, M.R. The Teachable Language Comprehender (TLC) is a program designed to be capable of being taught to \"comprehend\" English text.  When text which the program has not seen before is input to it, it comprehends that text by correctly relating each (explicit or implicit) assertion of the new text to a large memory.  This memory is a \"semantic network\" representing factual assertions about the world. The program also creates copies of the parts of its memory which have been found to relate to the new text, adapting and combining these copies to represent the meaning of the new text.  By this means, the meaning of all text the program successfully comprehends is encoded into the same format as that of the memory.  In this form it can be added into the memory. Both factual assertions for the memory and the capabilities for correctly relating text to the memory\\'s prior content are to be taught to the program as they are needed.  TLC presently contains a relatively small number of examples of such assertions and capabilities, but within the system, notations for expressing either of these are provided.  Thus the program now corresponds to a general process for comprehending language, and it provides a methodology for adding the additional information this process requires to actually comprehend text of any particular kind. The memory structure and comprehension process of TLC allow new factual assertions and capabilities for relating text to such stored assertions and capabilities for relating text to such stored assertions to generalize automatically. That is, once such an assertion or capability is put into the system, it becomes available to help comprehend a great many other sentences in the future. ']\n",
            "Query: This paper discusses the origins of library networks and traces their development in the United States in the late 1960s through the present. The concept of resource sharing, with particular attention to the inter- library loan and programs for the cooperative acquisition and storage of materials, is examined in relationship to library networks.  In particular, attention is given to the question of how these two major components of library cooperation, which have tended to be separate, might become more closely integrated.\n",
            "Score:  108.99916351220156\n",
            "Document:  ['Information Network Prospects in the United States Becker, J. Unmistakable signs are pointing the way toward the creation sometime soon of a national information network in the United States.  The concept of a national network implies the interconnection of existing information systems and libraries through communications.  Certainly one of the great strengths of this nation is the great array of intellectual, scholarly, and research resources to be found in its libraries and information centers. Without integration and close cooperation, however, these resources will remain a series of separate, insulated institutions.  But if maximum communication can be established among them, this array can be converted into a national resource of immense value to citizens throughout the country. ']\n",
            "Query: This paper presents a method of normalizations of English titles and their retrieval.  The title expressed by a noun phrase or a noun clause is converted to a function-expression by parsing.  For the retrieval with a reasonable recall rate as well as a high precision rate, the function- expression is transformed to a predicate-governor form, and then normalized to a standard form.  Therefrom, various items are extracted and recorded in a hierarchical tree-like inverted file.  In order to keep the recall rate in a reasonable value, several retrieval stages are implemented based on the key-term and case-label matching.  The retrieval is controlled by the preciseness of the specification of case-labels for each key-term.\n",
            "Score:  150.04460370825794\n",
            "Document:  [\"Some Aspects of Developing and Studying a Descriptor Information Language for General Technology Shemakin, Yu. I. The methods and results of an endeavor to develop an information retrieval language for automatic retrieval systems meant for handling a polytechnical document collection are described.. The descriptor dictionary includes general and special terms, both single-word and phrase terms, which is conducive to higher recall and relevance; it comprises a classified index and a lexico-semantic index as well as tables of generic relations.. The size of the dictionary is 5,542 descriptors and 3,073 keywords.. The indexing procedure includes:  analysis of document content and its characterization by keywords elicited from natural text; and creation of the search pattern using the descriptor dictionary.. The techniques are described which are applied to analyze the documents into semantic aspects that constitute the elements of the formalized model of a document's condensed content.. The procedure employed to translate a text into the retrieval language comprises selection of words both from the title and the body of the document.. Main principles for retrieval efficiency determination using mathematical-statistic methods are given.. Tests on multi-subject collections show a probability of 85-% recall and 70-% relevance at a standard deviation of 25%.. These findings have been corroborated by the results of the basic experiment on a file of up to 2,500 search patterns using 42 requests..  Among the factors of losses there are the poor quality of abstracts (into cards) and the absence of a single abstracting procedure; it is proposed that abstractors should be in future charged with writing abstracts in keywords and, ultimately, in the descriptor language.. The experimental results attest to the feasibility and practical sensibility of creating a multi-disciplinary information retrieval system to be based on a broad-scope descriptor dictionary and on the suggested methods for document and request indexing.. \"]\n",
            "Query: A generalization of the notion of ATN grammar, called a cascaded ATN (CATN), is prescribed.  CATN's permit a decomposition of complex language understanding behavior into a sequence of cooperating ATN's with separate domain of responsibility, where each stage (called an ATN transducer) takes its input from the output of the previous stage.  The paper includes an extensive discjussion of the principles of factoring-conceptual factoring reduces the number of places that a given fact needs to be represented in a grammar, and hypothesis factoring reduces the number of distinct hypotheses that have to be considered during parsing.\n",
            "Score:  124.35079139032865\n",
            "Document:  ['On Relevance, Probabilistic Indexing and Information Retrieval Maron, M. E. Kuhns, J. L. This paper reports on a novel technique for literature indexing and searching in a mechanized library system.. The notion of relevance is taken as the key concept in the theory of information retrieval and a comparative concept of relevance is explicated in terms of the theory of probability.. The resulting technique called \"Probabilistic Indexing,\" allows a computing machine, given a request for information, to make a statistical inference and derive a number (called the \"relevance number\") for each document, which is a measure of the probability that the document will satisfy the given request ranked according to their probable relevance.. The paper goes on to show that whereas in a conventional library system the cross-referencing (\"see\" and \"see also\") is based solely on the \"semantical closeness\" between index terms, statistical measures of closeness between index terms can be defined and computed.. Thus, given an arbitrary request consisting of one (or many) index term(s), a machine can elaborate on it to increase the probability of selecting relevant documents that would not otherwise have been selected.. Finally, the paper suggests an interpretation of the whole library problem as one where the request is considered as a clue on the basis of which the library system makes a concatenated statistical inference in order to provide as an output an ordered list of those documents which most probably satisfy the information needs of the user.. ']\n",
            "Query: Algorithms are given to process partially specified queries in a compressed database system.  The proposed methods handle effectively queries that use either whole words or word fragments as language elements. The methods are compared and critically evaluated in terms of the design and retrieval costs.  The analyses show that the method which exploits the interdependence of fragments as well as the relevance of fragments to records in the file has maximum design cost and least retrieval cost.\n",
            "Score:  99.2095905956589\n",
            "Document:  ['A Graph-Theoretic Algorithm for Matching Chemical Structures Sussenguth, E.H., Jr. There are many chemical retrieval systems which process the first type of request efficiently.  Most of these systems are also capable of handling certain fragment requests; however, the fragments which can be processed are frequently of a restricted nature.  For example, in retrieval systems which are based on linear ciphers, only those fragments which are explicit in the cipher are readily detected.  To allow a completely general specification of fragments it seems inevitable that a detailed atom-by-atom comparison is required of the query and library structures.  A technique for making such detailed comparisons is presented in this report.  This technique is novel in that it avoids the excessive backtracking ad restarting required by other atom-by-atom matching procedures. Before giving the details of the proposed algorithm, some definitions are reviewed and a brief example is presented to illustrate the over-all concepts.  Then the flow diagram of the algorithm is explained in terms of additional examples.  Finally, the mechanization of the algorithm for a digital computer is discussed. This report is a condensed version of the original, which gives a generalization and comprehensive description of the algorithm, proofs of convergence and related topics, and applications other than chemical retrieval systems. ']\n",
            "Query: From the detailed analysis of eight previously published mathematical models, a general formulation of Bradford's distribution can be deduced as follows:  y = a log(x + c) + b, where y is the ratio of the cumulative frequency of articles to the total number of articles and x is the ratio of the rank of journals to the total number of journals.  The parameters a, b, and c are the slope, the intercept, and the shift in a straight line to log rank, respectively.  Each of the eight models is a special case of the general formulation and is one of five types of formulation.  In order to estimate three unknown parameters, a statistical method using root-weighted square error is proposed.  A comparative experiment using 11 databases suggests that the fifth type of formulation with three unknown parameters is the best fit to the observed data.  A further experiment shows that the deletion of the droop data leads to a more accurate value of parameters and less error.\n",
            "Score:  242.78459609763934\n",
            "Document:  [\"Library Optimum Sandison, A. Sir,-In his recent article B.C. Brookes propounds an ingenious mathematical framework to determine which periodical volumes a library should hold.  He is careful to point out that the selection will need regular review and revision, in case the value of the aging factor a or the contents of the Bradford set change from year to year.  There is as yet very little experimental evidence on the consistency of either.  Such limited evidence as there is suggests that the aging factor is reasonably constant.  But the position of the Bradfod set is less satisfactory.  The Nature Conservancy librarians (J. M. Weingott and S. M. Penny, unpublished) have lent me a list of titles cited in the Journal of Ecology three or more times in 1955-56, and a similar list for 1965-66. There are 150 periodical titles in the two lists, but only forty-two (28%) appear in both.  Of the thirty-three titles cited nine or more times in either year, only eight (25%) attained that level in both, and twelve were cited less than three times in the other year.  The Kendall rank correlation coefficient between the two years is 0.18 and not significant. There is another major practical problem. The article assumes that the data analyzed to obtain aging or utility factors and Bradford sets are valid parameters of the relative value of the literature to the readers.  There is no mention of the type of data to use.  The reader who sought guidance from the earlier literature cited would find practical techniques described in which analyses of citation frequencies are used to calculate utilities discussed in terms of library use.  Krauze and Hillinger have discussed the difference between citations in one article and future citations to that article.  Their work implies a more complex relation between a and u than Brookes suggests.  In any case, the validity of citations for forecasting library consultations remains unproven, and there are prima facie reasons why the relationship is not necessarily close.  For example, one item in a list of references is often intended to lead to a chain of earlier papers.  Again, each citation represents an author's selection from a wider group most of which he has consulted in a library.  In neither case is there any inherent reason for similarity of age distribution or of pool of titles between the list of citations and the items read by the author or his readers. \"]\n",
            "Query: The lexical problems in large information systems are created by the necessity of handling a great number of names and their interrelations. Such lexical problems are not covered completely by the concept data dictionaries, which are mostly concerned with database scheme design rather than the execution of operations.  In this paper we introduce our view of a lexical subsystem as a separate component in an information system architecture, to deal with linguistic and control functions concerning the lexical problems in local and network environments.  The lexical suybsystem is a special efficiently organized program package, which plays the role of a \"linguistic filter\" in a broad sense for lexically incorrect queries, promotes integration of databases and information retrieval systems, and facilitates the creation of local information systems.  We hope that lexical subsystems can become productive for any large, especially distributed, information system.\n",
            "Score:  158.34188685636215\n",
            "Document:  ['Issues in Semantics Lakhuti, D.G. The present collection of articles discusses three basic problems:  the typological classification of information retrieval languages, the formal method of lexical semantic research, and textual semantics. Problems connected with lexical word meaning, the building up of semantic fields using computers, and automatic indexing are considered. ']\n",
            "Query: The relational model has received increasing attention during the past decade.  Its advantages include simplicity, consistency, and a sound theoretical basis.  In this article, the naturalness of viewing information retrieval relationally is demonstrated.  The relational model is presented, and the relational organization of a bibliographical database is shown. The notion of normalization is introduced and first, second, third, and fourth normal forms are demonstrated.  Relational languages are discussed, including the relational calculus, relational algebra, and SEQUEL. Numerous examples pertinent to information retrieval are presented in these relational languages.  Advantages of the relational approach to information retrieval are noted.\n",
            "Score:  139.94972443029306\n",
            "Document:  ['The Aberrystwyth Index Languages Test Keen, Michael E. Reports a laboratory comparision of the effectiveness and efficiency of five index languages in the subject area of library and information science; three post-co-ordinate languages, Compressed Term, Uncontrolled, and Hierarchically Structured, and two pre-co-ordinate ones, Hierarchically Structures and Relational Indexing.. Eight test comparisons were made, and factors studied were index language specificity and linkage, indexing specificity and exhaustivity, method of co-ordination, the precision devices of partitioning and relational operators, and the provision of context in the search file.. Full details of the test and retrieval results are presented.. ']\n",
            "Query: This paper describes an architectural approach that provides information exchange across a broad spectrum of user applications and office automation offerings.  Some of the architectures described herein are currently implemented in existing IBM products.  These and other architectures will provide the basis for document interchange capability between products such as the IBM 5520 Administrative System, the IBM System/370 Distributed Office Support System (DISOSS), and the IBM Displaywriter System. Specifically described is a document distribution architecture and its associated data streams and others.  A general overview of the architectures as opposed to a detailed technical description is provided.  The architectures described are protocols for interchange between application processes; they do not address the specific user interface.  The document distribution architectures utilize SNA for data transmission and communications control facilities.\n",
            "Score:  131.3823708159976\n",
            "Document:  ['On-Line  Serials Control System in a Large Biomedical Library; 1) Description of the System Fayollat, James An on-line serials control system with particular emphasis on storage and maintenance concepts is described.. The system, operational since January, 1971, has evolved from a former batch card system and remains completely compatible with it.. The system allows real-time display and updating of all elements of the file.. Consequently all check-in, bindery, and claims operations, as well as new entries and data field changes are accomplished on a real-time basis.. All programs are in PL/1.. Required equipment is an IBM time-shared facility with 100 K memory available for the applications programs, and IBM 2260 display units.. This article is the first of three.. The second is concerned with an analysis of inverted file retrieval features and the third compares the operation of the on-line with the batch system, comparable manual operations, and discusses costs.. ']\n",
            "Query: A technique is described for automatic reformulation of boolean queries.  Based on patron relevance judgements of an initial retrieval, prevalence measures are derived for terms appearing in the retrieved set of documents that reflect a term's distribution among the relevant and non-relevant documents.  These measures are then used to guide the construction of a boolean query for a subsequent retrieval.  To illustrate the technique, a series of tests is described of its application to a small data base in an experimental environment.  Results compare favourably with feedback as employed in a SMART-type system.  MOre extensive testing is suggested to validate the technique.\n",
            "Score:  133.06225433446252\n",
            "Document:  ['Performance and Cost of \"Free-Text\" Search systems Kent, A.K. The purpose of an information-retrieval system is to provide the user with citations relevant to his query.  Since the user is the only person competent to make the final judgement of relevance it is natural to suppose that the selection of items from a data base will lead to two kinds of retrieval error.  The extent of these errors is expressed by the familiar measures of performance, precision and recall.  Precision measures the failure of the system to retrieve only relevant documents while recall measures its failure to retrieve all relevant documents actually present in the data base.  It is difficult to visualize a situation in which a user would find advantage in being provided with irrelevant citations.  From the user\\'s point of view, therefore, a system which offers less than 100 per cent precision is a deficient system. ']\n",
            "Query: This paper is intended to propose a new methodological approach to the conception and development of natural language understanding systems. This new contribution is supported by the design, implementation, and experimentation of DONAU:  a general purpose domain oriented natural language understanding system developed and presently running at the Milan Polytechnic Artificial Intelligence Project.  The system is based on a two level modular architecture intended to overcome the lack of flexibility and generality often pointed out in many existing systems, and to facilitate the exchange of results and actual experiences between different projects. The horizontal level allows an independent and parallel development of the single segments of the system (syntactic analyser, information extractor, legality controller).  The vertical level ensures the possibility of changing (enlarging or redefining) the definition of the semantic domain on which each particular version of the system is oriented and specialized in a simple, incremental, and user-oriented way.  In the paper the general architecture of the system and the mode of operation of each segment are illustrated in detail.  Linguistic models, knowledge representation, and parsing algorithms are described and illustrated by means of selected examples.  Performance evaluations of the system in the application version on data base inquiry are reported and discussed.  Promising directions for future research are presented in the conclusions.\n",
            "Score:  277.52027760945646\n",
            "Document:  ['A Mathematical Theory of Communication Shannon, C.E. The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication.  A basis for such a theory is contained in the important papers of Nyquist and Hartley on this subject.  In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information. The fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point.  Frequently the messages have meaning; that is they refer to or are correlated according to some system with certain physical or conceptual entities.  These semantic aspects of communication are irrelevant to the engineering problem.  The significant aspect is that the actual message is one selected from a set of possible messages.  The system must be designed to operate for each possible selection, not just the one which will actually be chosen since this is unknown at the time of design. ']\n",
            "Query: Approximate matching of strings is reviewed with the aim of surveying techniques suitable for finding an item in a database when there may be a spelling mistake or other error in the keyword.  The methods found are classified as either equivalence or similarity problems. Equivalence problems are seen to be readily solved using canonical forms. For similarity problems difference measures are surveyed, with a full description of the well-established dynamic programming method relating this to the approach using probabilities and likelihoods.  Searches for approximate matches in large sets using a difference function are seen to be an open problem still, though several promising ideas have been suggested.  Approximate matching (error correction) during parsing is briefly reviewed.\n",
            "Score:  109.76635521217841\n",
            "Document:  ['Current approaches to classification and clump-finding at the Cambridge Language Research Unit Sparck-Jones, K. Jackson, David Computer programs for automatic classification are a desideratum in many fields.. Work on suitable procedures for handling large bodies of object/ property descriptions has been in progress at the Cambridge Language Research Unit for some years: this paper describes the current series of general-purpose programs which have been developed there, in which classes or \"clamps\" of objects are obtained, using a similarity matrix, by a simple iterative scan of the universe of objects, distributing them in such a way that an appropriate cohesion function is minimized.. This actual clump-finding process is embedded in a overall package in which the information given by a classification is manipulated in a variety of ways.. The current applications of the programs, especially for information retrieval, are described.. ']\n",
            "Query: A prototype system is created that integrates a microfiche catalog into an online computer system for bibliographic control.  Costs and operational data are collected and analyzed.  The system permits the more economical microfiche storage of catalog records than would be feasible for comparable online magnetic disk storage.  Experimental tests demonstrate the feasibility of the online microfiche catalog system for use in library technical services and retrieval of bibliographic data.  The primary result of the project is the creation of a completely operational facility, including all equipment, software, procedures, and data bases necessary to demonstrate the system.  A second set of results is derived from the experimental use of the system and the evaluation of costs and times for various operations.  The cost effectiveness of the online microfiche catalog is demonstrated.\n",
            "Score:  195.55247752528606\n",
            "Document:  ['Project Intrex: A General Review Overhage, Carl F. J. Reintjes, J. Francis A comprehensive review of the experimental information storage and retrieval system developed by Project Intrex is presented, together with a description of major results and conclusions that were derived through use of the system.. Salient features of the Intrex system included an argumented catalog stored in an online interactive computer in combination with full-text storage on microfiche.. Guaranteed access to full text at remote allocations was provided through use of an automatic fiche storage and retrieval system that was computer-controlled.. Discussed in the paper are the details of the catalog structure, user experiments, economic studies and information-system networking.. ']\n",
            "Query: The question is asked whether it is feasible to use subsets of natural languages as query languages for data bases in actual applications using the question answering system \"USER SPECIALTY LANGUAGES\" (USL). Methods of evaluating a natural language based information system will be discussed.  The results (error and language structure evaluation) suggest how to form the general architecture of application systems which use a subset of German as query language.\n",
            "Score:  93.20570135934437\n",
            "Document:  ['Natural Language Question - Answering System: 1969 Simmons, Robert F. Recent experiments in programming natural language question-answering system are reviewed to summarize the methods that have been developed for syntactic, semantic, and logical analysis of English strings.. It is concluded that at least minimally effective  techniques have been devised for answering questions from natural language subsets in small scale experimental systems and that a useful paradigm has evolved to guide research efforts in the field.. Current approaches to semantic analysis and logical inference are seen to be effective beginnings but of questionable generality with respect either to subtle aspects of meaning or to applications over large subset of English.. Generalizing from current small-scale experiments to language processing systems based on dictionaries with thousands of entries - with correspondingly large grammars and semantic systems - may entail a new order of complexity and require the invention and development of entirely different approaches to semantic analysis and question answering.. ']\n",
            "Query: In 1978 Collier presented some hypothetical data on economic aspects of the use of online services as compared with subscriptions to printed services in libraries.  Collier's view of the economics of online searching seems misleadingly pessimistic because:  1.  It looks only at costs but not at effectiveness in comparing the two modes of access and searching.  An analysis combining cost and effectiveness aspects (i.e., a cost-effectiveness analysis) would give a completely different picture.  2.  The way the cost data are presented is grossly unfair to the online mode of access and use.  This work contains corrected information regarding online and printed services in libraries.\n",
            "Score:  155.24783481798545\n",
            "Document:  ['ASIDIC Survey of Information Center Services Williams, M.E. The data in that survey covered the year 1971.  Many recipients of the 1972 document have requested updated information.  Accordingly, the ASIDIC Cooperative Data Management Committee initiated a new survey. The questionnaires were mailed out in January of 1975 and responses came in throughout the year.  Questionnaires were sent to all member organizations of ASIDIC and EUSIDIC.  Questionnaires were also sent to individual members of ASIS SIG/SDI and SIG/UOI. Responses received throughout 1975 were checked and tabulated in 1976.  Because of the time delay in producing the final compilation the reader is warned against using this survey as an up-to-date source for information as to which centers are processing which data bases. Of the 116 responding organizations 75 process data bases and 41 use data base services either as end users or as brokers.  Of the 75 that process data bases (i.e., spin tapes) 51 (68%) are members of ASIDIC and/or EUSIDIC.  This survey provides representative data for data base processing organizations.  The use of online search services was relatively new in 1974 hence data regarding online users would not be representative of the 1976 online situation. ']\n",
            "Query: Many information scientists are concerned with the operation of document retrieval systems serving scientists in various fields.  The scientists served by these systems are often members of what have been called invisible colleges, groups of scientists in frequent communication with one another and involved with highly specialized subject matters.  Often such groups are considered to share an intellectual perspective regarding this subject matter, which is sometimes referred to as a paradigm.  The purpose of this paper is to show how it is possible to identify paradigms, using the techniques of citation analysis.  I will operationalize the notion of paradigm as a 'consensual structure of concepts in a field.' Suppose we have obtained a set of papers pertaining to some topic.  Already knowing something about the field, we read each text and mark passages in which certain specific concepts are used or discussed.  For example, we might find that a concept designated 'A' appears in some sub-set of the papers.  Suppose further that we identify those papers in which concepts 'A' and 'B' are used together in the same papers in a certain specified manner. Clearly not all concepts will combine in a natural way, and not all authors combining concepts 'A' and 'B' will do so in the same way, though some predominant mode may emerge.  For a set of n concepts their structure is given by the totality of admissible combinations of concepts taken from two to n at a time.  The frequency with which a given combination occurs in the sample of papers on the topic is a measure of the degree of consensus regarding the particular concept combination within the corpus.  For concepts taken two at a time, the structure can be displayed as a graph with concepts as nodes and the relations between them represented as lines (arcs) connecting the nodes.  This definition of concept structure is similar to the semantic network of artificial intelligence except that in our approach a measure of consensus weights each arc of the graph.\n",
            "Score:  389.63097190639434\n",
            "Document:  ['A Mathematical Theory of Communication Shannon, C.E. The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication.  A basis for such a theory is contained in the important papers of Nyquist and Hartley on this subject.  In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information. The fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point.  Frequently the messages have meaning; that is they refer to or are correlated according to some system with certain physical or conceptual entities.  These semantic aspects of communication are irrelevant to the engineering problem.  The significant aspect is that the actual message is one selected from a set of possible messages.  The system must be designed to operate for each possible selection, not just the one which will actually be chosen since this is unknown at the time of design. ']\n",
            "Query: One mode of online retrieval in Scisearch or Social Scisearch involves entering pairs of authors' names believed to be jointly cited by subsequent writers and retrieving papers in which cocitations occur.  Six pairs were formed with the names of four authors prominent in the social indicators movement (Bauer, Duncan, Land, and Sheldon).  Documents by the four were not specified.  It was thought that the pair Duncan and Land would retrieve papers in which indicator-type data would be integrated with path-analytic causal modeling.  All other pairs seemed likely to retrieve a \"general social indicators\" literature.  The 298 retrieved papers confirmed expectattions.  It was found that 121 papers generally cited social indicators (SI) documents by the input authors and frequently had SI language in their titles.  Other signs of content also identified them as papers of the SI movement.  The 177 papers retrieved on Duncan and Land generally cited causal modeling documents by the input pair and were path-analytic in nature.  As expected, they were relatively \"harder\" than the first group of papers, although the two groups are akin and are formally linked through citations in certain papers.  An additional result is that papers citing at least three of the input authors tend to be overviews of the SI movement.\n",
            "Score:  231.35120838798616\n",
            "Document:  [\"Professional Standing and the Reception of Scientific Discoveries Cole, S. The Matthew Effect occurs when scientists receive differential recognition for a particular scientific contribution depending on their location in the stratification system.  Merton originally introduced the concept to explain the allocation of credit among authors of multiple discoveries or collaborators.  In this paper the concept is generalized to apply to all scientific work.  If the Matthew Effect were to operate, the reception of papers of equal quality should be influenced by the location of their authors in the stratification system. To test this hypothesis, data are drawn from several studies of similar design.  In each study we control for the number of citations papers received at time 2.  This enables us to look at groups of papers that were judged to be roughly equal in quality at time 2. We then see whether there were any differences in the reception of these papers at time 1 depending upon various aspects of the author's location in the stratification system.  All the data indicate that assessed quality of papers at time 2 is a more important determinant of a paper's initial reception than any of the stratification variables.  However, the speed of diffusion of papers of equal quality is influenced by the reputation of the author based on past work that is being heavily utilized at the time of a new discovery.  The Matthew Effect also operates for those scientists located at prestigious points of the social system of science.  All other stratification variables, including eminence as measured by receipt of awards did not influence the speed of diffusion.  Data are presented that indicate that top papers written by high-ranking scientists are no more likely to be widely diffused early than are top papers by low- ranking scientists.  The Matthew Effect also serves to focus attention on the work of little-known men who collaborate with scientists of high repute and to increase retroactively the visibility of the early work of scientists who go on to greater fame.  A discussion is included of the relevance of these data for the study of resistance to scientific discoveries. \"]\n",
            "Query: The number of databases, records contained in databases and the online use of databases has increased dramatically over the past several years, bringing the 1979 totals for bibliographic, bioliographic-related, and natural language databases to 528.  These 528 databases contain 148 million records.  Some 4 million online searches were conducted via the major U.S. and Canadian systems in 1979.\n",
            "Score:  94.25103508357591\n",
            "Document:  ['CA Condensates as a Retrospective Search Tool\\tA Commentary Hansen, Inge Berg A retrospective test search on 1 year of CA Condensates was carried out in order to calculate the cost per profile and to get an impression of how CA Condensates would suffice as a database for a retrospective use.. Some means of improving the search strategy by means of the CAS Standard Distribution Format were investigated.. The question is raised whether the costs and efforts presently devoted to research regarding retrospective searches on large free-text databases are justified in view of the low average precision ratios generally observed for free text databases and the very high number of references of potential interest retrieved.. ']\n",
            "Query: A method of iterative searching, using the results of one iteration search to formulate the next iteration search, was applied to a full-text database consisting of some 2400 documents and 1,3000,000 text-words of Hebrew and Aramaic.  The iterative method consists of clustering the documents returned in an iteration, using weighting by proximity and by frequency simultaneously. The process produces searchonyms, which are terms synonymous to keywords in the context of a single query.  Augumenting or replacing keywords by searchonyms via manual or automatic feedback leads to the formulation of the next iteration search.  The results of the experiment are consistent with those of an earlier small-scale experiment on an English database, and indicate that in contrast to global clustering where the size of matrices limits applications to small databases and improvements are doubtful, local metrical methods appear to be well suited to arbitrarily large databases, improving precision and recall simultaneously.  Further experiments using more test-queries run on even larger databases should be made to collect further evidence as to the performance of these methods.\n",
            "Score:  207.37877656920566\n",
            "Document:  [\"Some Aspects of Developing and Studying a Descriptor Information Language for General Technology Shemakin, Yu. I. The methods and results of an endeavor to develop an information retrieval language for automatic retrieval systems meant for handling a polytechnical document collection are described.. The descriptor dictionary includes general and special terms, both single-word and phrase terms, which is conducive to higher recall and relevance; it comprises a classified index and a lexico-semantic index as well as tables of generic relations.. The size of the dictionary is 5,542 descriptors and 3,073 keywords.. The indexing procedure includes:  analysis of document content and its characterization by keywords elicited from natural text; and creation of the search pattern using the descriptor dictionary.. The techniques are described which are applied to analyze the documents into semantic aspects that constitute the elements of the formalized model of a document's condensed content.. The procedure employed to translate a text into the retrieval language comprises selection of words both from the title and the body of the document.. Main principles for retrieval efficiency determination using mathematical-statistic methods are given.. Tests on multi-subject collections show a probability of 85-% recall and 70-% relevance at a standard deviation of 25%.. These findings have been corroborated by the results of the basic experiment on a file of up to 2,500 search patterns using 42 requests..  Among the factors of losses there are the poor quality of abstracts (into cards) and the absence of a single abstracting procedure; it is proposed that abstractors should be in future charged with writing abstracts in keywords and, ultimately, in the descriptor language.. The experimental results attest to the feasibility and practical sensibility of creating a multi-disciplinary information retrieval system to be based on a broad-scope descriptor dictionary and on the suggested methods for document and request indexing.. \"]\n",
            "Query: REFLES is a microcomputer-based system for data retrieval in library environments.  The problem of information retrieval is discussed from a theoretical point of view, followed by an analysis of the reference process and data thereby gathered, leading to a description of REFLES in terms of its hardware and software.  REFLES, a prototype system at present, currently functions in a test environment.  Examples of data contained in the system and of its use are presented.  Future considerations and speculations on other versions of the system conclude the paper.\n",
            "Score:  130.91926650701188\n",
            "Document:  ['Data Retrieval Systems:  Specifics and Problems Shtein, V. S. The essential differences between data retrieval system and document retrieval systems are considered.. The notion of \"fact\" is discussed, analyzing the influence of the definition adopted on the structure of a data retrieval system.. A proposition is advanced that a factographic JRS is a rudimentary but indispensable form on the way to a logical information system.. The latter type of system by a capability for automatic analysis of input data and synthesis of new information.. The problem of the information retrieval language for data retrieval system is discussed, as is its machine organization, intricately tied up with the specifics and functions of a system of that kind.. ']\n",
            "Query: A major deficiency of traditional Boolean systems is their inability to represent the varying degrees to which a document may be written on a subject. In this article we isolate a number of criteria that should be met by any Boolean system generalized to have a weighting capability.  It is proven that only one weighting rule satisfies these conditions--that associated with fuzzy- set theory--and that this weighting scheme satisfies most of the other properties associated with Boolean algebra as well.  Probabilistic weighting is then introduced as an alternative approach and the two systems compared. In the limit of zero/one weights, all systems considered converge to traditional Boolean retrieval.\n",
            "Score:  117.75528661384541\n",
            "Document:  ['A Probabilistic Search Strategy for MEDLARS Miller, William L. One technique for searching a Co-ordinate Index is to compare each reference with a Boolean expression of index terms.. This divides the file into retrieved and not-retrieved references.. An alternative is to assign each reference score calculated from its index terms and to retrieve the N highest scoring references in the file.. This scoring technique has several advantages in theory, and it performed slightly better in a retrieval test with N equal to the number of references retrieved by the corresponding Boolean search.. In the test a minimum value of N = 10 was used, and when less then this number of references matched the Boolean search requirement, the Scoring technique successfully widened the score of the search and retrieved twice as many relevant references as the Boolean searches.. ']\n",
            "Query: Several papers have appeared that have analyzed recent developments in the problem of processing, in a document retrieval system, queries expressed as Boolean expressions.  The purpose of this paper is to continue that analysis. We shall show that the concept of threshold values resolves the problems inherent with relevance weights.  Moreover, we shall explore possible evaluation mechanisms for retrieval of documents, based on fuzzy-set-theoretic considerations.\n",
            "Score:  73.24528093051848\n",
            "Document:  ['Progress in Documentation: The Development of Precis: A Theoretical and Technical History Austin, D. Before starting to trace the development of PRECIS to its theoretical beginnings I shall describe the system briefly in its present form.  This will serve not only as an introduction for those who are not familiar with the system, but will also help to explain the relevance of some of the historical sections which follow, in which we shall see how a machine-produced alphabetical indexing system, based on a syntax derived from a study of natural language, developed out of research into principles for a new general classification. PRECIS, or the PREserved Context Indexing System, differs in some respects from traditional alphabetical indexes and lists of subject headings. Like the system developed by Coates for the British Technology Index, PRECIS consists essentially of a set of working procedures, not a prescribed list of terms or phrases.  The system is firmly based upon the concept of an open-ended vocabulary, which means that terms can be admitted into the index at any time, as soon as they have been encountered in literature. Once a term has been admitted, its relationships with other terms are handled in two different ways, distinguished as the syntactical and the semantic sides of the system. ']\n",
            "Query: There has been a good deal of work on information retrieval systems that have continuous weights assigned to the index terms that describe the records in the database, and/or to the query terms that describe the user queries. Recent articles have analyzed retrieval systems with continuous weights of either type and/or with a Boolean structure for the queries.  They have also suggested criteria which such systems ought to satisfy and record evaluation mechanisms which partially satisfy these criteria.  We offer a more careful analysis, based on a generalization of the discrete weights.  We also look at the weights from an entirely different approach involving thresholds, and we generate an improved evaluation mechanism which seems to fulfill a larger subset of the desired criteria than previous mechanisms.  This new mechanism allows the user to attach a \"threshold\" to the query term.\n",
            "Score:  153.17054196004167\n",
            "Document:  ['The Multiterm Index:  A New Concept in Information Storage and Retrieval Skolnik, H. An index not only can be a creative communication medium, it needs to be in a research and development environment.  A creative index is achievable if the relationship and association of things and actions, one to another, can be communicated as a continuous function vis-a-vis the real world of science and technology. A chemist does not think of a chemical, for example, ethyl alcohol, in isolation.  Ethyl alcohol is not merely a word or a term without dimensions to a chemist.  It is a concept that he associates with or relates to a product, a reactant, a solvent in a reaction, a use, a property, etc.  It is within the semantics of his conceptual needs that he would like to use an index to retrieve those documents he needs.  He wants more than documents, however, from the index.  He wants the index to direct him to those documents which are pertinent to his problem.  He wants the index to help him to generate thoughts and to suggest new combinations. He wants the index to help him in terms of his language, logic, and semantics and through a generic or specific approach, whichever occurs to him first.  He wants the ability to browse among the terms to discover the term that is on the tip of his tongue or recessed in his memory.  These are the criteria an index must satisfy if it is to be a creative medium of communication. ']\n",
            "Query: Online retrieval systems may be difficult to use, especially by end users, because of heterogeneity and complexity.  Investigations have concerned the concept of a translating computer interface as a means to simplify access to, and operation of, heterogeneous bibliographic retrieval systems and databases.  The interface allows users to make requests in a common language. These requests are translated by the interface into the appropriate commands for whatever system is being interrogated.  System responses may also be transformed by the interface into a common form before being given to the users.  Thus, the network of different systems is made to look like a single \"virtual\" system to the user.  The interface also provides instruction and other search aids for the user.  The philosophy, design, and implementation of an experimental interface named CONIT are described.\n",
            "Score:  171.7923497177856\n",
            "Document:  ['User Assessment of Computer-Based Bibliographic Retrieval Services Carmon, J.L. Park, M.K. The academic users of the bibliographic information dissemination center were surveyed to determine the ways in which the search results were being used, the impact which the services had had on professional activities such as research and instruction, the interface between the computer-based retrieval and the traditional form of library resources, and the effect of document overlap between different data bases.  The survey results indicate that the dissemination services are being used by a large portion of the faculty and the graduate students within the University System of Georgia, with an average of 3 to 5 people seeing the bibliography from each search question.  Over 97% of the respondees indicated some or substantial contribution to their professional activities, with the major contributions being a savings or more efficient use of time and broadened subject coverage.  The users indicated several changes in library use habits as a result of the computer-based searches, among them more direct access to the primary literature and increased use of library resources as they had been made aware of new sources and media - e.g., microforms.  Percentage responses on these and related topics are presented. ']\n",
            "Query: The evaluation of the concept of a translating compuyter interface for simplifying operation of multiple, heterogenous online bibliographic retrieval systems has been undertaken.  An experimental retrieval system, named CONIT, was built and tested under controlled conditions with inexperienced end users.  A detailed analysis of the experimental usages showed that users were able to master interface operation sufficiently well to find relevant document references.  Success was attributed, in part, to a simple command language, adequate online instruction, and a simplified natural-language, keyword/stem approach to searching.  It is concluded that operational interfaces of the type studied can provide for increased usability of existing system in a cost effective manner, especially for searchers. Furthermore, more advanced interfaces based on improved instruction and automated search strategy techniques could further enhance retrieval effectiveness for a wide class of users.\n",
            "Score:  147.47820406258322\n",
            "Document:  ['Functions of a Man-Machine Interactive Information Retrieval System Williams, J. H. Jr. An effective man-machine interactive retrieval system is not achieved by simply placing a terminal on each end of an existing machine retrieval system.. An interactive system requires a sequence of steps in which man and machine alternately take action.. It should also provide different levels of services to experienced and inexperienced searchers, recognize the difference between a narrow and broad query, furnish clues as to the next direction to be searched, recognize the data base dynamically as the searcher changes his viewpoint, provide a ranking of responses in the most likely sequence and offer the searcher the option of overriding the ranking when a particular term is of extreme significance.. An online interactive system meeting many of these needs has been developed and tested.. The objectives of the development of this system, BROWSER, was to investigate the effectiveness of a free-form query with a combinatorial search algorithm and the effectiveness of various techniques and components to facilitate online browsing.. ']\n",
            "Query: This paper notes the benefits accruing from interaction between computerized retrieval systems and micrographic retrieval systems.  It reviews current state of automated micrographic retrieval technology.  The conclusion is that with a combination of advances in communications technology, and sophisticated indexing input from libraries and information scientists, the new generation of automated micrographs devices may constitute the on-line document retrieval systems of the future.\n",
            "Score:  84.79394107977515\n",
            "Document:  ['Information Retrieval On-Line Lancaster, F.W. This book deals with on-line systems for bibliographic search and retrieval.  The literature on this subject is increasing rapidly and new systems are appearing all the time.  We have attempted to provide a broad survey of the characteristics, capabilities, and limitations of present systems.  Our emphasis is on the design, evaluation, and use of on-line retrieval systems, primarily from the viewpoint of the planner and manager of information services.  It is oriented toward the \"intellectual\" aspects of information retrieval rather than the hardware or programming aspects.  We hope that this book may have some value for all students of library and information science. ']\n",
            "Query: Conventional information retrieval processes are largely based on data movement, pointer manipulations and integer arithmetic; more refined retrieval algorithms may in addition benefit from substantial computational power.  In the present study a number of parallel processing methods are described that serve to enhance retrieval services.  In conventional retrieval environments parallel list processing and parallel search facilities are of greatest interest.  In more advanced systems, the use of array processors also proves beneficial.  Various information retrieval processes are examined and evidence is given to demonstrate the usefulness of parallel processing and fast computational facilities in information retrieval.\n",
            "Score:  107.24963985843505\n",
            "Document:  ['A Note on the Pseudo-Mathematics of Relevance Taube, M. Recently a number of articles, books, and reports dealing with information systems, i.e., document retrieval systems, have advanced the doctrine that such systems are to be evaluated in terms of the degree or percentage of relevancy they provide. Although there seems to be little agreement on what relevance means, and some doubt that it is quantifiable, there is, nevertheless, a growing agreement that a fixed and formal relationship exists between the relevance and the recall performance of any system.  Thus, we will find in the literature both a frankly subjective notion of relevance as reported by individual users, and equations, curves, and mathematical formulations which presumably provide numerical measures of the recall and relevance characteristics of information systems.  This phenomenon of shifting back and forth from an admittedly subjective and non-mathematical term to equations in which the same term is given a mathematical value or a mathematical definition has its ancient parallel in discussions of probability.  One cannot, of course, legislate the meaning of a term.  It all depends, as Alice pointed out, on \"who is master,\" the user or the term.  On the other hand, the use of a single term in the same document to cover two or more distinct meanings, especially when such a usage is designed to secure the acceptance of a doctrine by attributing to it mathematical validity which it does not have, represents a more serious situation than merely careless ambiguity. ']\n",
            "Query: The frequency characteristics of terms in the documents of a collection have been used as indicators of term importance for content analysis and indexing purposes.  In particular, very rare or very frequent terms are normally believed to be less effective than medium-frequency terms.  Recently automatic indexing theories have been devised that use not only the term frequency characteristics but also the relevance properties of the terms. The major term-weighting theories are first briefly reviewed.  The term precision and term utility weights that are based on the occurrence characteristics of the terms in the relevant, as opposed to the nonrelevant, documents of a collection are then introduced.  Methods are suggested for estimating the relevance properties of the terms based on their overall occurrence characteristics in the collection.  Finally, experimental evaluation results are shown comparing the weighting systems using the term relevance properties with the more conventional frequency-based methodologies.\n",
            "Score:  207.55187953633825\n",
            "Document:  ['On the Specification of Term Values in Automatic Indexing Salton, G. Yang, C. S. The existing practice in automatic indexing is reviewed, and it is shown that the standard theories for the specification of term values (or weights) are not adequate.. New techniques are introduced for the assignment of weights to index terms, based on the characteristics of individual document collections.. The effectiveness of some of the proposed methods is evaluated.. ']\n",
            "Query: This paper describes the design and implementation of an \"electronic filing machine,\" a machine which is capable of storing large numbers of \"unstructured\" documents in such a way a particular document may be easily and quickly retrieved.  A functional distributed architecture permits the implementation of the system in a mixture of hardware and software.\n",
            "Score:  74.76897287576591\n",
            "Document:  ['Fields of Information on Library of Congress Catalog Cards: Analysis of a Random Sample, 1950-1964 Avram, H.D. Guiles, K.D. Meade, G.T. The Information Systems Office (ISO) of the Library of Congress has as its mission the development and implementation of the main automation program for the Library and the co-ordination of all LC automation efforts. One of the primary activities in this effort is a system-development study concentrating on the central bibliographic operations, that is, acquisitions, cataloging, reference, etc.  This study is now in its early stages, and it is too soon to predict the actual system that will evolve. As an adjunct to this study an analysis of the potential uses of and problems involved in the machine processing of cataloging data was begun.  One aspect of the analysis was the design of a preliminary machine- readable catalog record.  The results of this work are in a report issued by the ISO as its \"Planning Memorandum Number 3.\" ']\n",
            "Query: This paper tackles the problem of how one might select further search terms, using relevance feedback, given the search terms in the query.  These search terms are extracted from a maximum spanning tree connecting all the terms in the index term vocabulary.  A number of different spanning trees are generated from a variety of association measures.  The retrieval effectiveness for the different spanning trees is shown to be approximately the same.  Effectiveness is measured in terms of precision and recall, and the retrieval tests are done on three different test collections.\n",
            "Score:  137.97365576460896\n",
            "Document:  ['An Experiment in Index Term Frequency Svenonius, Elaine This paper presents an experimental study of index-term frequency as a factor in retrieval performance.. The frequency of an index term, or its \"breadth\" as it is called here, is the number of postings made to the term in a given collection.. The question is asked: Of index terms assigned to documents, which function most effectively in retrieval, the most term or popular terms, or those which are used relatively infrequently? The experiment is a retrieval experiment and uses the Cranfield-Salton data.. Breadth of indexing is varied by nonrandomly deleting terms from documents.. Retrieval output is evaluated using the Expected Search Length measure of retrieval effectiveness as well as the usual precision and recall.. The Wilcoxen Test is used to determine the statistical significance of the different indexings.. The results show that the \"optimal\" breadth of indexing is a variable, depending on user needs: if a few documents are wanted or high precision is desired, then narrow terms are more effective than broad ones; if, on the other hand, all or most relevant documents are wanted, then broad terms are better.. An argument, however, can be made for the quality of narrow terms, since when these terms are deleted precision never improves, whereas deleting broad terms always results in a higher precision.. A corollary experiment is carried out to compare two indexings of the same average breadth where one indexing consists of semantically appropriate terms - terms taken from the document title - and the other consists of merely \"reasonable\" index terms.. The result suggest that title-term indexing is qualifiedly superior.. ']\n",
            "Query: Indexing quality determines whether the information content of an indexed document is accurately represented.  Indexing effectiveness measures whether an indexed document is correctly retrieved every time it is relevant to a query.  Measurement of these criteria is cumbersome and costly; data base producers therefore prefer inter-indexer consistency as a measure of indexing quality or effectiveness.  The present article assesses the validity of this substitution in various environments.\n",
            "Score:  84.06766236313632\n",
            "Document:  ['Performance and Cost of \"Free-Text\" Search systems Kent, A.K. The purpose of an information-retrieval system is to provide the user with citations relevant to his query.  Since the user is the only person competent to make the final judgement of relevance it is natural to suppose that the selection of items from a data base will lead to two kinds of retrieval error.  The extent of these errors is expressed by the familiar measures of performance, precision and recall.  Precision measures the failure of the system to retrieve only relevant documents while recall measures its failure to retrieve all relevant documents actually present in the data base.  It is difficult to visualize a situation in which a user would find advantage in being provided with irrelevant citations.  From the user\\'s point of view, therefore, a system which offers less than 100 per cent precision is a deficient system. ']\n",
            "Query: A set of experiments was conducted to determine the suitability of the Colon Classification as a foundation for the automated analysis, representation and retrieval of primary information from the full text of documents.  Primary information is that information embodied in the text of a document, as opposed to secondary information which is generally in such forms as:  an abstract, a table of contents, or an index. Full text databases were created in two subject areas and queries solicited from specialists in each area.  An automated full text indexing system, along with four automated passage retrieval systems, was created to test the various features of the Colon Classification.  Two Boolean-based systems and one simple word occurrence system were created in order to compare the retrieval results against types of systems which are in more common use.  The systems' retrieval performances were measured using recall and precision and the mean expected search length reduction factors. Overall, it was found that the Colon Classification-based systems did not perform significantly better than the other systems.\n",
            "Score:  196.6058985809425\n",
            "Document:  ['Text Searching Retrieval of Answer-Sentences and Other Answer-Passages O\\'Connor, John Some new text searching retrieval techniques are described which retrieve not documents but sentences from documents and sometimes (on occasions determined by the computer) multi-sentence sequences.. Since the goal of the techniques is retrieval of answer-providing documents, \"answer-passages\" are retrieved.. An \"answer-passage\" is a passage which is either answer-providing or \"answer-indicative,\" i.e., it permits inferring that the document containing it is answer-providing.. In most cases answer-sentences, i.e., single-sentence answer-passages, are retrieved.. This has great advantages for screening retrieval output.. Two new automatic procedures for measuring closeness of relation between clue words in a sentence are described.. One approximates syntactic closeness by counting the number of intervening \"syntactic joints\" (roughly speaking, prepositions, conjunctions and punctuation marks) between successive clue words.. The other measure uses word proximity in a new way.. The two measures perform about equally well.. The computer uses \"enclosure\" and \"connector words\" for determining when a multi-sentence passage should be retrieved.. However, no procedure was found in this study for retrieving multi-paragraph answer-passages, which were the only answer-passages occurring in 6% of the papers.. In a test of the techniques they failed to retrieve two answer-providing documents (7% of those to be retrieved) because of one multi-paragraph answer-passage and one complete failure of clue word selection.. For the other answer-providing documents they retrieved at all recall levels with greater precision than SMART, which has produced the best previously reported recall-precision results.. The retrieval questions (mostly from real users) and documents used in this study were from the field of information science.. The results of the study are surprisingly good for retrieval in such a \"soft science,\" and it is reasonable to hope that in less \"soft\" sciences and technologies the techniques described will work even better.. On this basis a dissemination and retrieval system of the near future is predicted.. ']\n",
            "Query: A study was carried out of the relationship between the vocabulary of user queries and the vocabulary of documents relevant to the queries, and the value of adding to the document description record in a retrieval system keywords from previous queries for which the document had proved useful. Two test databases incorporating user query keywords were implemented at the School of Library and Information Science, University of Western Ontario.  Clustering of the documents via title and user keywords, a statistical analysis of title-user keyword co-occurrences, and retrieval tests were used to examine the effect of the added keywords.  Results showed the impracticality of the procedure in an operational setting, but indicated the value of analyses with sample data in the development and maintenance of keyword dictionaries and thesauri.\n",
            "Score:  188.38833644855322\n",
            "Document:  ['A Decision Theory View of the Information Retrieval Situation: An Operations Research Approach Kraft, Donald H. A decision theory approach is used to model the information retrieval decision problem of which documents to retrieve from a library collection in response to a specific user query for information.. A thorough discussion of decision theory, including the components of the alternatives,states-of-nature, outcomes, and evaluations - as well as of the optimization process under the cases of certainty, risk, and uncertainty - is presented.. Bayesian statistics are also discussed to show how prior information about the various documents via classification analysis can affect the decision process under risk.. An example problem is used to illustrate the decision theory approach and to compare tha overall performance of the retrieval system under risk with and without document classification information.. Thus, the operations research technique of decision theory is used to model the retrieval decision process, illustrate how important evaluation is, and to demonstrate the value of prior information via document classification analysis.. Moreover, the paper presents, in a somewhat tutorial mode, an overall framework for considering the information retrieval decision problem, incorporating the aspects of cost-effectiveness and alternative evaluation, which allows one to better understand the contributions made by many researchers in this crucial area.. ']\n",
            "Query: A technique of online instruction and assistance to bibliographic data base searchers called Individualized Instruction for Data Access (IIDA) is being developed by Drexel University.  IIDA assists searchers by providing feedback based on real-time analysis while searches are being performed. Extensive help facilities which draw on this analysis are available to users.  Much of the project's experimental work, as described elsewhere, is concerned with the process of searching and the behavior of searchers. This paper will largely address itself to the project's computer system, which is being developed by subcontract with the Franklin Institute's Science Information Services.\n",
            "Score:  87.87628382420057\n",
            "Document:  [\"Letter to the Editor:  Assessment of Information Services Davison, P.s. May we please raise four questions which are important at the present time when government policy on information retrieval is being considered? These arise from results recently produced by SDC which are germane to Dr. Somerfield's paper on 'Computer-based Information Services' (Aslib Proceedings, 20, 12, 542-50 (1968)), and to OSTI's work in this field. The SDC is making comparisons of the efficiency of various published indexes and other sources of scientific information and the first results of rigorously checked comparisons are becoming available for a case study on the subject of 'Computers Related to Mass Spectrometry'.  This results from an extensive literature search prepared by combining and collating results of searches in twelve of the world's major indexes to chemistry and spectroscopy, including searches of SDC's own data bank files.  Nearly two hundred unique references on 'Computers Related to Mass Spectrometry' were found and are being checked individually for relevance going back to the original paper or asking expert opinion where necessary. \"]\n",
            "Query: It is shown that the mapping of a particular area of science, in this case information science, can be done using authors as units of analysis and the cocitations of pairs of authors as the variable that indicates their \"distances\" from each other.  The analysis assumes that the more two authors are cited together, the closer the relationship between them.  The raw data are cocitation counts drawn online from Social Scisearch (Social Sciences Citation Index) over the period 1972-1979.  GThe resulting map shows (1) identifiable author groups (akin to \"schools\") of information science, (2) locations of these groups with respect to each other, (3) the degree of centrality and peripherality of authors within groups, (4) proximities of authors within group and across group boundaries (\"border authors\" who seem to connect various areas of research), and (5) positions of authors with respect to the map's axes, which were arbitrarily set spanning the most divergent groups in order to aid interpretation.  Cocitation analysis of authors offers a new technique that might contribute to the understanding of intellectual structure in the sciences and possibly in other areas to the extent that those areas rely on serial publications.  The technique establishes authors, as well as documents, as an effective unit in analyzing subject specialties.\n",
            "Score:  241.20316869604946\n",
            "Document:  ['Computational Analysis of Scoring Models for R and D Project Selection Moore, J.R. Baker, N.R. Several authors have proposed using scoring models for prescriptive analysis of the R and D project selection decision problem.  This research indicates that these models do not meet with important practical requirements.  For example, many authors recommend a multiplicative index, over an additive index, in order to generate a wide range of project scores.  The additive index is shown to have important advantages over the multiplicative index. The most serious shortcoming in the models, however, is the relatively arbitrary fashion in which the models have been constructed and the failure of the model builders to recognize the impact of certain structural considerations on resulting project scores.  Comparative analyses relating project rankings produced by scoring models to rankings produced by a profitability index and by a linear programming model demonstrate that the performance of the scoring model is highly sensitive to decisions made during the development of the model.  Considerations such as (1) the underlying distributions of project data, (2) time preferences, (3) the number of ranking intervals or categories, and (4) the width of the intervals, all have important implications for final project scores and associated rankings. ']\n",
            "Query: The \"Office of the Future,\" \"Office Technology,\" \"Word Processing,\" \"Electronic Mail,\" \"Electronic Communications,\" \"Convergence,\" \"Information Management.\"  These are all terms included in the current list of buzz words used to describe current activities in the office technology area.  The high level of investment in factories and plants and the ever-increasing fight to improve productivity by automating the dull, routine jobs are usually quoted and compared with the extremely low investment in improving and automating the equally tedious routine jobs in the office environment; the investment in the factory is quoted as being ten times greater per employee than in the office.  This, however, is changing rapidly and investment on a large scale is already taking place in manhy areas as present-day inflation bites hard, forcing many companies and organizations to take a much closer look at their office operations.\n",
            "Score:  152.53620244077257\n",
            "Document:  [\"A Dynamic Programming Approach to R and D Budgeting and Project Selection Hess, Sidney W. Contemporary models of research and development are incomplete in that they ignore the many reappraisals and budgeting decisions that occur in the time between a project's proposal and its commercialization.. The sequential decision aspects of project budgeting are particularly important since 1) the research expenditure is usually an order of magnitude less than the irrevocable investment for commercialization and 2) an allocation to a project today does not presuppose continuation of the project into future periods.. The research and development budgeting problem is structured to take into account the sequential decision characteristic.. Utilizing the technique of dynamic programming, methods are developed to determine optimal project budgets when the aggregate research and development budget is either constrained or unconstrained.. These models also suggest a rational explanation of the patterns of project expenditures over time that one observes in practice.. Finally, some of the shortcomings of the developed methods which inhibit their practical application are discussed.. \"]\n",
            "Query: An automated document clustering procedure is described which does not require the use of an inter-document similarity matrix and which is independent of the order in which the documents are processed.  The procedure makes use of an initial set of clusters which is derived from certain of the terms in the indexing vocabulary used to characterise the documents in the file.  The retrieval effectiveness obtained using the clustered file is compared with that obtained from serial searching and from use of the single-linkage clustering method.\n",
            "Score:  126.59341090279136\n",
            "Document:  ['Deriving Term Relations for a Corpus by Graph Theoretical Clusters Augustson, J.G. Minker, J. We discuss how alternative methods of automatic term clustering may provide insight into how terms are related within a corpus.  The work reported uses a corpus of 2267 documents that contain 3950 index terms.\\tA similarity matrix is developed using the document - term matrix.  A threshold level T is applied to the similarity matrix.  Entries in the matrix that are greater than or equal to the threshold level are set equal to one, and the remaining entries are set to zero. Three definitions are applied to the corresponding graph of each threshold matrix to develop clusters. These are, (1) the connected components of the graph, (2) the maximal complete subgraphs of the graph, and (3) the combined maximal complete subgraphs of the graph as described that show how insight may be gained into the term relations by varying the threshold levels and the cluster definitions. ']\n",
            "Query: A fast algorithm is described for comparing the lists of terms representing documents in automatic classification experiments.  The speed of the procedure arises from the fact that all of the non-zero-valued coefficicents for a given document are identified together, using an inverted file to the terms in the document collection.  The complexity and running time of the algorithm are compared with previously described procedures.\n",
            "Score:  97.58076486117562\n",
            "Document:  ['Utility of Automatic Classification Systems for Information Storage and Retrieval Litofsky, Barry Large-scale, on-line information storage and retrieval systems pose numerous problems above those encountered by smaller systems.. The more critical of these problems involve: degree of automation, flexibility, browsability, storage space, and retrieval time.. A step toward the solution of these problems is presented here along with several demonstrations of feasibility and advantages.. The methodology on which this solution is based is that of a posteriori automatic classification of the document collection.. Feasibility is demonstrated by automatically classifying a file of 50,000 document descriptions.. The advantages of automatic classification are demonstrated by establishing methods for measuring the quality of classification systems and applying these measures to a number of different classification strategies.. By indexing the 50,000 documents by two independent methods, one manual and one automatic, it is shown that these advantages are not dependent upon the indexing method used.. It was found that among those automatic classification algorithms studied, one particular algorithm, CLASFY, consistently outperformed the others.. In addition, it was found that this algorithm produced classifications at least as good, with respect to the measured established in this dissertation, as the a priori, manual classification system currently in use with the aforementioned file.. The actual classification schedules produced by CLASFY in classifying a file of almost 50,000 document descriptions into 265 categories are included as an appendix to this dissertation.. ']\n"
          ]
        }
      ]
    }
  ]
}